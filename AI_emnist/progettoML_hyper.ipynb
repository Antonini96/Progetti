{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ccef343-f9e4-479c-8cc1-37e659f021fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79f232e6-355e-40e7-96b9-8cda26bfc7ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f5bb1d8-bc57-40b6-ba0a-92380180060f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\3204480343\\Downloads\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fe6e6c8-7c59-403e-b43b-d3cef1c64549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"emnist-letters.csv\") #carica i dati in df\n",
    "\n",
    "#separa le immagini dalle etichette e effettua reshaping in 28x28\n",
    "X = df.iloc[:,1:].to_numpy().reshape(-1, 28, 28, order=\"F\")\n",
    "y = df.iloc[:,0].to_numpy()-1  # Sottrai 1 per avere etichette da 0 a 25\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2) #random_state=42\n",
    "\n",
    "#utilizziamo i primi 5000 campioni come validation set\n",
    "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255.\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5564b5a-0e2f-449b-80e0-4260145ee9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "class_names = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\",\n",
    "              \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\",]\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12092144-e623-48ee-8967-b05c3c6b3806",
   "metadata": {},
   "source": [
    "build_model crea e configura un modello sequenziale utilizzando TensorFlow/Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4460d60a-f031-4e6a-a50e-fe80f0da2753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model (n_hidden=3, n_units=100, learning_rate=0.01):\n",
    "    model = keras.models.Sequential() #Crea un modello sequenziale vuoto, a cui aggiungerai strati successivamente.\n",
    "    model.add(keras.layers.Flatten(input_shape=[28, 28])) #layer di input\n",
    "    for i in range(n_hidden): #crea i layer nascosti\n",
    "        model.add(keras.layers.Dense(n_units, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(26, activation=\"softmax\")) #ultimo layer da utilizzare la f di attivazione softmax\n",
    "\n",
    "    model.summary() #mi stampo il modello utilizzato in quel momento\n",
    "    \n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", #loss utilizzata\n",
    "              optimizer=keras.optimizers.SGD(lr=learning_rate), #ottimizzatore\n",
    "              metrics=[\"accuracy\"]) #metrica utilizzata\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76439f00-003b-4ec9-9e93-d2c8d2628660",
   "metadata": {},
   "source": [
    "algoritmi di ricerca degli iperparametri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ef8c0b-8396-47e1-b40d-a68994a39103",
   "metadata": {},
   "source": [
    "Durante la ricerca casuale degli iperparametri, verranno addestrati diversi modelli con combinazioni diverse di iperparametri e valutati tramite cross-validation. Il risultato finale sar√† il modello con la combinazione ottimale di iperparametri secondo i criteri specificati durante la configurazione del RandomizedSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a193808d-dc99-4c19-86dd-261f30a62963",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 12 candidates, totalling 24 fits\n",
      "WARNING:tensorflow:From C:\\Users\\3204480343\\Downloads\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 26)                20410     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20410 (79.73 KB)\n",
      "Trainable params: 20410 (79.73 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:From C:\\Users\\3204480343\\Downloads\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\3204480343\\Downloads\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\3204480343\\Downloads\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\3204480343\\Downloads\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1032/1032 [==============================] - 4s 3ms/step - loss: 2.1895 - accuracy: 0.4558 - val_loss: 1.6872 - val_accuracy: 0.5670\n",
      "Epoch 2/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.5339 - accuracy: 0.5956 - val_loss: 1.4503 - val_accuracy: 0.6078\n",
      "Epoch 3/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.3766 - accuracy: 0.6224 - val_loss: 1.3536 - val_accuracy: 0.6240\n",
      "Epoch 4/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.2986 - accuracy: 0.6378 - val_loss: 1.2980 - val_accuracy: 0.6368\n",
      "Epoch 5/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.2497 - accuracy: 0.6496 - val_loss: 1.2623 - val_accuracy: 0.6438\n",
      "Epoch 6/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.2147 - accuracy: 0.6592 - val_loss: 1.2326 - val_accuracy: 0.6536\n",
      "Epoch 7/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.1884 - accuracy: 0.6657 - val_loss: 1.2128 - val_accuracy: 0.6592\n",
      "Epoch 8/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.1677 - accuracy: 0.6708 - val_loss: 1.1978 - val_accuracy: 0.6622\n",
      "Epoch 9/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.1506 - accuracy: 0.6750 - val_loss: 1.1833 - val_accuracy: 0.6666\n",
      "Epoch 10/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.1360 - accuracy: 0.6803 - val_loss: 1.1715 - val_accuracy: 0.6694\n",
      "Epoch 11/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.1236 - accuracy: 0.6847 - val_loss: 1.1635 - val_accuracy: 0.6694\n",
      "Epoch 12/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.1136 - accuracy: 0.6863 - val_loss: 1.1534 - val_accuracy: 0.6756\n",
      "Epoch 13/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.1040 - accuracy: 0.6893 - val_loss: 1.1468 - val_accuracy: 0.6752\n",
      "Epoch 14/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.0955 - accuracy: 0.6925 - val_loss: 1.1420 - val_accuracy: 0.6746\n",
      "Epoch 15/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.0883 - accuracy: 0.6944 - val_loss: 1.1361 - val_accuracy: 0.6788\n",
      "Epoch 16/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0815 - accuracy: 0.6973 - val_loss: 1.1304 - val_accuracy: 0.6822\n",
      "Epoch 17/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0756 - accuracy: 0.6980 - val_loss: 1.1261 - val_accuracy: 0.6830\n",
      "Epoch 18/30\n",
      "1032/1032 [==============================] - 3s 2ms/step - loss: 1.0696 - accuracy: 0.7000 - val_loss: 1.1217 - val_accuracy: 0.6840\n",
      "Epoch 19/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0648 - accuracy: 0.7022 - val_loss: 1.1196 - val_accuracy: 0.6836\n",
      "Epoch 20/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.0600 - accuracy: 0.7024 - val_loss: 1.1157 - val_accuracy: 0.6854\n",
      "Epoch 21/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.0556 - accuracy: 0.7033 - val_loss: 1.1125 - val_accuracy: 0.6882\n",
      "Epoch 22/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.0515 - accuracy: 0.7048 - val_loss: 1.1099 - val_accuracy: 0.6874\n",
      "Epoch 23/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0472 - accuracy: 0.7073 - val_loss: 1.1072 - val_accuracy: 0.6906\n",
      "Epoch 24/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0439 - accuracy: 0.7081 - val_loss: 1.1050 - val_accuracy: 0.6922\n",
      "Epoch 25/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0403 - accuracy: 0.7084 - val_loss: 1.1028 - val_accuracy: 0.6910\n",
      "Epoch 26/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0372 - accuracy: 0.7106 - val_loss: 1.0997 - val_accuracy: 0.6928\n",
      "Epoch 27/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0342 - accuracy: 0.7102 - val_loss: 1.1000 - val_accuracy: 0.6932\n",
      "Epoch 28/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0312 - accuracy: 0.7099 - val_loss: 1.0970 - val_accuracy: 0.6930\n",
      "Epoch 29/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0284 - accuracy: 0.7126 - val_loss: 1.0950 - val_accuracy: 0.6966\n",
      "Epoch 30/30\n",
      "1032/1032 [==============================] - 3s 2ms/step - loss: 1.0256 - accuracy: 0.7128 - val_loss: 1.0967 - val_accuracy: 0.6934\n",
      "1032/1032 [==============================] - 2s 2ms/step\n",
      "[CV] END learning_rate=0.0030533915117977035, n_hidden=0, n_units=283; total time= 1.3min\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 26)                20410     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20410 (79.73 KB)\n",
      "Trainable params: 20410 (79.73 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 2.1918 - accuracy: 0.4585 - val_loss: 1.6968 - val_accuracy: 0.5718\n",
      "Epoch 2/30\n",
      "1032/1032 [==============================] - 3s 2ms/step - loss: 1.5410 - accuracy: 0.5975 - val_loss: 1.4570 - val_accuracy: 0.6098\n",
      "Epoch 3/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.3836 - accuracy: 0.6239 - val_loss: 1.3612 - val_accuracy: 0.6300\n",
      "Epoch 4/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.3054 - accuracy: 0.6386 - val_loss: 1.3028 - val_accuracy: 0.6414\n",
      "Epoch 5/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.2561 - accuracy: 0.6505 - val_loss: 1.2647 - val_accuracy: 0.6500\n",
      "Epoch 6/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.2214 - accuracy: 0.6578 - val_loss: 1.2387 - val_accuracy: 0.6530\n",
      "Epoch 7/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.1953 - accuracy: 0.6642 - val_loss: 1.2176 - val_accuracy: 0.6604\n",
      "Epoch 8/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.1738 - accuracy: 0.6689 - val_loss: 1.2004 - val_accuracy: 0.6642\n",
      "Epoch 9/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.1573 - accuracy: 0.6736 - val_loss: 1.1869 - val_accuracy: 0.6708\n",
      "Epoch 10/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.1431 - accuracy: 0.6781 - val_loss: 1.1734 - val_accuracy: 0.6726\n",
      "Epoch 11/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.1310 - accuracy: 0.6819 - val_loss: 1.1652 - val_accuracy: 0.6776\n",
      "Epoch 12/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.1203 - accuracy: 0.6857 - val_loss: 1.1554 - val_accuracy: 0.6794\n",
      "Epoch 13/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.1112 - accuracy: 0.6875 - val_loss: 1.1499 - val_accuracy: 0.6820\n",
      "Epoch 14/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.1030 - accuracy: 0.6902 - val_loss: 1.1438 - val_accuracy: 0.6834\n",
      "Epoch 15/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.0957 - accuracy: 0.6924 - val_loss: 1.1380 - val_accuracy: 0.6840\n",
      "Epoch 16/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.0891 - accuracy: 0.6942 - val_loss: 1.1337 - val_accuracy: 0.6860\n",
      "Epoch 17/30\n",
      "1032/1032 [==============================] - 3s 2ms/step - loss: 1.0831 - accuracy: 0.6955 - val_loss: 1.1297 - val_accuracy: 0.6850\n",
      "Epoch 18/30\n",
      "1032/1032 [==============================] - 3s 2ms/step - loss: 1.0780 - accuracy: 0.6972 - val_loss: 1.1240 - val_accuracy: 0.6908\n",
      "Epoch 19/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0728 - accuracy: 0.6986 - val_loss: 1.1222 - val_accuracy: 0.6886\n",
      "Epoch 20/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0682 - accuracy: 0.7002 - val_loss: 1.1181 - val_accuracy: 0.6918\n",
      "Epoch 21/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0636 - accuracy: 0.7008 - val_loss: 1.1150 - val_accuracy: 0.6922\n",
      "Epoch 22/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.0600 - accuracy: 0.7028 - val_loss: 1.1110 - val_accuracy: 0.6934\n",
      "Epoch 23/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.0560 - accuracy: 0.7034 - val_loss: 1.1093 - val_accuracy: 0.6912\n",
      "Epoch 24/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.0525 - accuracy: 0.7052 - val_loss: 1.1072 - val_accuracy: 0.6958\n",
      "Epoch 25/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0492 - accuracy: 0.7055 - val_loss: 1.1065 - val_accuracy: 0.6916\n",
      "Epoch 26/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0463 - accuracy: 0.7055 - val_loss: 1.1021 - val_accuracy: 0.6954\n",
      "Epoch 27/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0431 - accuracy: 0.7076 - val_loss: 1.1012 - val_accuracy: 0.6954\n",
      "Epoch 28/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.0403 - accuracy: 0.7088 - val_loss: 1.0995 - val_accuracy: 0.6968\n",
      "Epoch 29/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0377 - accuracy: 0.7085 - val_loss: 1.0980 - val_accuracy: 0.6962\n",
      "Epoch 30/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0348 - accuracy: 0.7090 - val_loss: 1.0962 - val_accuracy: 0.6974\n",
      "1032/1032 [==============================] - 2s 1ms/step\n",
      "[CV] END learning_rate=0.0030533915117977035, n_hidden=0, n_units=283; total time= 1.3min\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_2 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 26)                20410     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20410 (79.73 KB)\n",
      "Trainable params: 20410 (79.73 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1032/1032 [==============================] - 3s 2ms/step - loss: 2.1927 - accuracy: 0.4511 - val_loss: 1.6915 - val_accuracy: 0.5692\n",
      "Epoch 2/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.5404 - accuracy: 0.5937 - val_loss: 1.4534 - val_accuracy: 0.6068\n",
      "Epoch 3/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.3813 - accuracy: 0.6198 - val_loss: 1.3555 - val_accuracy: 0.6266\n",
      "Epoch 4/30\n",
      "1032/1032 [==============================] - 3s 2ms/step - loss: 1.3021 - accuracy: 0.6376 - val_loss: 1.2989 - val_accuracy: 0.6382\n",
      "Epoch 5/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.2524 - accuracy: 0.6491 - val_loss: 1.2627 - val_accuracy: 0.6484\n",
      "Epoch 6/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.2169 - accuracy: 0.6578 - val_loss: 1.2325 - val_accuracy: 0.6576\n",
      "Epoch 7/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.1902 - accuracy: 0.6651 - val_loss: 1.2125 - val_accuracy: 0.6616\n",
      "Epoch 8/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.1693 - accuracy: 0.6709 - val_loss: 1.1972 - val_accuracy: 0.6624\n",
      "Epoch 9/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.1520 - accuracy: 0.6756 - val_loss: 1.1828 - val_accuracy: 0.6684\n",
      "Epoch 10/30\n",
      "1032/1032 [==============================] - 3s 2ms/step - loss: 1.1373 - accuracy: 0.6802 - val_loss: 1.1707 - val_accuracy: 0.6740\n",
      "Epoch 11/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.1249 - accuracy: 0.6838 - val_loss: 1.1625 - val_accuracy: 0.6726\n",
      "Epoch 12/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.1147 - accuracy: 0.6866 - val_loss: 1.1526 - val_accuracy: 0.6770\n",
      "Epoch 13/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.1051 - accuracy: 0.6883 - val_loss: 1.1458 - val_accuracy: 0.6772\n",
      "Epoch 14/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0966 - accuracy: 0.6919 - val_loss: 1.1410 - val_accuracy: 0.6794\n",
      "Epoch 15/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0893 - accuracy: 0.6936 - val_loss: 1.1351 - val_accuracy: 0.6820\n",
      "Epoch 16/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0825 - accuracy: 0.6955 - val_loss: 1.1293 - val_accuracy: 0.6864\n",
      "Epoch 17/30\n",
      "1032/1032 [==============================] - 3s 2ms/step - loss: 1.0766 - accuracy: 0.6973 - val_loss: 1.1250 - val_accuracy: 0.6858\n",
      "Epoch 18/30\n",
      "1032/1032 [==============================] - 3s 2ms/step - loss: 1.0706 - accuracy: 0.6990 - val_loss: 1.1206 - val_accuracy: 0.6880\n",
      "Epoch 19/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0658 - accuracy: 0.7008 - val_loss: 1.1184 - val_accuracy: 0.6862\n",
      "Epoch 20/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0610 - accuracy: 0.7018 - val_loss: 1.1145 - val_accuracy: 0.6846\n",
      "Epoch 21/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0566 - accuracy: 0.7036 - val_loss: 1.1113 - val_accuracy: 0.6882\n",
      "Epoch 22/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0525 - accuracy: 0.7035 - val_loss: 1.1087 - val_accuracy: 0.6914\n",
      "Epoch 23/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0482 - accuracy: 0.7061 - val_loss: 1.1063 - val_accuracy: 0.6904\n",
      "Epoch 24/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0448 - accuracy: 0.7069 - val_loss: 1.1039 - val_accuracy: 0.6922\n",
      "Epoch 25/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.0413 - accuracy: 0.7067 - val_loss: 1.1017 - val_accuracy: 0.6908\n",
      "Epoch 26/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0382 - accuracy: 0.7098 - val_loss: 1.0986 - val_accuracy: 0.6910\n",
      "Epoch 27/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0352 - accuracy: 0.7087 - val_loss: 1.0988 - val_accuracy: 0.6958\n",
      "Epoch 28/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0322 - accuracy: 0.7091 - val_loss: 1.0959 - val_accuracy: 0.6954\n",
      "Epoch 29/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0294 - accuracy: 0.7111 - val_loss: 1.0938 - val_accuracy: 0.6962\n",
      "Epoch 30/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0265 - accuracy: 0.7117 - val_loss: 1.0955 - val_accuracy: 0.6954\n",
      "1032/1032 [==============================] - 2s 2ms/step\n",
      "[CV] END learning_rate=0.01944191524550166, n_hidden=0, n_units=31; total time= 1.2min\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_3 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 26)                20410     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20410 (79.73 KB)\n",
      "Trainable params: 20410 (79.73 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 2.1915 - accuracy: 0.4624 - val_loss: 1.7010 - val_accuracy: 0.5666\n",
      "Epoch 2/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.5403 - accuracy: 0.5955 - val_loss: 1.4598 - val_accuracy: 0.6062\n",
      "Epoch 3/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.3829 - accuracy: 0.6228 - val_loss: 1.3629 - val_accuracy: 0.6226\n",
      "Epoch 4/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.3045 - accuracy: 0.6384 - val_loss: 1.3038 - val_accuracy: 0.6378\n",
      "Epoch 5/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.2551 - accuracy: 0.6495 - val_loss: 1.2655 - val_accuracy: 0.6474\n",
      "Epoch 6/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.2204 - accuracy: 0.6586 - val_loss: 1.2389 - val_accuracy: 0.6560\n",
      "Epoch 7/30\n",
      "1032/1032 [==============================] - 3s 2ms/step - loss: 1.1944 - accuracy: 0.6651 - val_loss: 1.2179 - val_accuracy: 0.6648\n",
      "Epoch 8/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.1730 - accuracy: 0.6703 - val_loss: 1.2006 - val_accuracy: 0.6658\n",
      "Epoch 9/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.1566 - accuracy: 0.6748 - val_loss: 1.1868 - val_accuracy: 0.6708\n",
      "Epoch 10/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.1424 - accuracy: 0.6793 - val_loss: 1.1733 - val_accuracy: 0.6748\n",
      "Epoch 11/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.1303 - accuracy: 0.6825 - val_loss: 1.1650 - val_accuracy: 0.6780\n",
      "Epoch 12/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.1197 - accuracy: 0.6854 - val_loss: 1.1552 - val_accuracy: 0.6810\n",
      "Epoch 13/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.1107 - accuracy: 0.6879 - val_loss: 1.1495 - val_accuracy: 0.6814\n",
      "Epoch 14/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.1026 - accuracy: 0.6900 - val_loss: 1.1430 - val_accuracy: 0.6840\n",
      "Epoch 15/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0953 - accuracy: 0.6919 - val_loss: 1.1374 - val_accuracy: 0.6862\n",
      "Epoch 16/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0888 - accuracy: 0.6937 - val_loss: 1.1331 - val_accuracy: 0.6868\n",
      "Epoch 17/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0828 - accuracy: 0.6965 - val_loss: 1.1292 - val_accuracy: 0.6880\n",
      "Epoch 18/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0777 - accuracy: 0.6977 - val_loss: 1.1232 - val_accuracy: 0.6900\n",
      "Epoch 19/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0725 - accuracy: 0.6991 - val_loss: 1.1214 - val_accuracy: 0.6886\n",
      "Epoch 20/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0680 - accuracy: 0.7003 - val_loss: 1.1175 - val_accuracy: 0.6914\n",
      "Epoch 21/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0634 - accuracy: 0.7010 - val_loss: 1.1142 - val_accuracy: 0.6916\n",
      "Epoch 22/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0598 - accuracy: 0.7032 - val_loss: 1.1103 - val_accuracy: 0.6930\n",
      "Epoch 23/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0558 - accuracy: 0.7040 - val_loss: 1.1083 - val_accuracy: 0.6916\n",
      "Epoch 24/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0523 - accuracy: 0.7045 - val_loss: 1.1063 - val_accuracy: 0.6944\n",
      "Epoch 25/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0490 - accuracy: 0.7060 - val_loss: 1.1056 - val_accuracy: 0.6932\n",
      "Epoch 26/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0461 - accuracy: 0.7063 - val_loss: 1.1011 - val_accuracy: 0.6940\n",
      "Epoch 27/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0429 - accuracy: 0.7071 - val_loss: 1.1001 - val_accuracy: 0.6966\n",
      "Epoch 28/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0402 - accuracy: 0.7076 - val_loss: 1.0984 - val_accuracy: 0.6964\n",
      "Epoch 29/30\n",
      "1032/1032 [==============================] - 3s 2ms/step - loss: 1.0376 - accuracy: 0.7086 - val_loss: 1.0969 - val_accuracy: 0.6962\n",
      "Epoch 30/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0347 - accuracy: 0.7101 - val_loss: 1.0949 - val_accuracy: 0.6974\n",
      "1032/1032 [==============================] - 2s 1ms/step\n",
      "[CV] END learning_rate=0.01944191524550166, n_hidden=0, n_units=31; total time= 1.2min\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_4 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 173)               135805    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 26)                4524      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 140329 (548.16 KB)\n",
      "Trainable params: 140329 (548.16 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 2.0767 - accuracy: 0.4611 - val_loss: 1.4773 - val_accuracy: 0.5954\n",
      "Epoch 2/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.3137 - accuracy: 0.6285 - val_loss: 1.2465 - val_accuracy: 0.6446\n",
      "Epoch 3/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.1542 - accuracy: 0.6700 - val_loss: 1.1480 - val_accuracy: 0.6762\n",
      "Epoch 4/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.0652 - accuracy: 0.6976 - val_loss: 1.0738 - val_accuracy: 0.6954\n",
      "Epoch 5/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.9994 - accuracy: 0.7168 - val_loss: 1.0277 - val_accuracy: 0.7064\n",
      "Epoch 6/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.9430 - accuracy: 0.7322 - val_loss: 0.9692 - val_accuracy: 0.7246\n",
      "Epoch 7/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.8929 - accuracy: 0.7459 - val_loss: 0.9329 - val_accuracy: 0.7324\n",
      "Epoch 8/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.8483 - accuracy: 0.7604 - val_loss: 0.8955 - val_accuracy: 0.7450\n",
      "Epoch 9/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.8075 - accuracy: 0.7718 - val_loss: 0.8559 - val_accuracy: 0.7542\n",
      "Epoch 10/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.7697 - accuracy: 0.7837 - val_loss: 0.8272 - val_accuracy: 0.7678\n",
      "Epoch 11/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.7358 - accuracy: 0.7941 - val_loss: 0.7982 - val_accuracy: 0.7720\n",
      "Epoch 12/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.7062 - accuracy: 0.8004 - val_loss: 0.7723 - val_accuracy: 0.7752\n",
      "Epoch 13/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.6780 - accuracy: 0.8082 - val_loss: 0.7471 - val_accuracy: 0.7860\n",
      "Epoch 14/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.6525 - accuracy: 0.8149 - val_loss: 0.7307 - val_accuracy: 0.7908\n",
      "Epoch 15/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.6293 - accuracy: 0.8216 - val_loss: 0.7076 - val_accuracy: 0.7980\n",
      "Epoch 16/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.6079 - accuracy: 0.8280 - val_loss: 0.6913 - val_accuracy: 0.8000\n",
      "Epoch 17/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5884 - accuracy: 0.8324 - val_loss: 0.6739 - val_accuracy: 0.8054\n",
      "Epoch 18/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5705 - accuracy: 0.8374 - val_loss: 0.6607 - val_accuracy: 0.8082\n",
      "Epoch 19/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5541 - accuracy: 0.8427 - val_loss: 0.6483 - val_accuracy: 0.8104\n",
      "Epoch 20/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5387 - accuracy: 0.8462 - val_loss: 0.6362 - val_accuracy: 0.8132\n",
      "Epoch 21/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5248 - accuracy: 0.8514 - val_loss: 0.6277 - val_accuracy: 0.8158\n",
      "Epoch 22/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5113 - accuracy: 0.8545 - val_loss: 0.6136 - val_accuracy: 0.8190\n",
      "Epoch 23/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4983 - accuracy: 0.8585 - val_loss: 0.6053 - val_accuracy: 0.8180\n",
      "Epoch 24/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4872 - accuracy: 0.8611 - val_loss: 0.5979 - val_accuracy: 0.8244\n",
      "Epoch 25/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4760 - accuracy: 0.8638 - val_loss: 0.5915 - val_accuracy: 0.8254\n",
      "Epoch 26/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4657 - accuracy: 0.8672 - val_loss: 0.5812 - val_accuracy: 0.8266\n",
      "Epoch 27/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4558 - accuracy: 0.8693 - val_loss: 0.5782 - val_accuracy: 0.8278\n",
      "Epoch 28/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4468 - accuracy: 0.8727 - val_loss: 0.5691 - val_accuracy: 0.8308\n",
      "Epoch 29/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4378 - accuracy: 0.8739 - val_loss: 0.5623 - val_accuracy: 0.8330\n",
      "Epoch 30/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4295 - accuracy: 0.8769 - val_loss: 0.5599 - val_accuracy: 0.8340\n",
      "1032/1032 [==============================] - 2s 2ms/step\n",
      "[CV] END learning_rate=0.04556125739834199, n_hidden=1, n_units=173; total time= 1.5min\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_5 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 173)               135805    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 26)                4524      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 140329 (548.16 KB)\n",
      "Trainable params: 140329 (548.16 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1032/1032 [==============================] - 4s 3ms/step - loss: 2.0819 - accuracy: 0.4705 - val_loss: 1.4822 - val_accuracy: 0.6010\n",
      "Epoch 2/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.3203 - accuracy: 0.6274 - val_loss: 1.2397 - val_accuracy: 0.6538\n",
      "Epoch 3/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.1559 - accuracy: 0.6697 - val_loss: 1.1348 - val_accuracy: 0.6786\n",
      "Epoch 4/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.0636 - accuracy: 0.6960 - val_loss: 1.0597 - val_accuracy: 0.7036\n",
      "Epoch 5/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.9950 - accuracy: 0.7150 - val_loss: 1.0024 - val_accuracy: 0.7220\n",
      "Epoch 6/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.9384 - accuracy: 0.7319 - val_loss: 0.9571 - val_accuracy: 0.7336\n",
      "Epoch 7/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.8894 - accuracy: 0.7475 - val_loss: 0.9159 - val_accuracy: 0.7442\n",
      "Epoch 8/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.8446 - accuracy: 0.7607 - val_loss: 0.8726 - val_accuracy: 0.7560\n",
      "Epoch 9/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.8054 - accuracy: 0.7725 - val_loss: 0.8424 - val_accuracy: 0.7646\n",
      "Epoch 10/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.7690 - accuracy: 0.7833 - val_loss: 0.8041 - val_accuracy: 0.7752\n",
      "Epoch 11/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.7359 - accuracy: 0.7920 - val_loss: 0.7784 - val_accuracy: 0.7828\n",
      "Epoch 12/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.7048 - accuracy: 0.8018 - val_loss: 0.7506 - val_accuracy: 0.7918\n",
      "Epoch 13/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.6774 - accuracy: 0.8075 - val_loss: 0.7318 - val_accuracy: 0.7962\n",
      "Epoch 14/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.6513 - accuracy: 0.8152 - val_loss: 0.7097 - val_accuracy: 0.7994\n",
      "Epoch 15/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.6284 - accuracy: 0.8215 - val_loss: 0.6921 - val_accuracy: 0.8048\n",
      "Epoch 16/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.6069 - accuracy: 0.8273 - val_loss: 0.6756 - val_accuracy: 0.8056\n",
      "Epoch 17/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5869 - accuracy: 0.8318 - val_loss: 0.6583 - val_accuracy: 0.8114\n",
      "Epoch 18/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5691 - accuracy: 0.8382 - val_loss: 0.6424 - val_accuracy: 0.8150\n",
      "Epoch 19/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5518 - accuracy: 0.8427 - val_loss: 0.6309 - val_accuracy: 0.8166\n",
      "Epoch 20/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5358 - accuracy: 0.8462 - val_loss: 0.6217 - val_accuracy: 0.8190\n",
      "Epoch 21/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.5212 - accuracy: 0.8522 - val_loss: 0.6095 - val_accuracy: 0.8210\n",
      "Epoch 22/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5078 - accuracy: 0.8544 - val_loss: 0.5981 - val_accuracy: 0.8254\n",
      "Epoch 23/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4943 - accuracy: 0.8570 - val_loss: 0.5903 - val_accuracy: 0.8262\n",
      "Epoch 24/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4822 - accuracy: 0.8603 - val_loss: 0.5803 - val_accuracy: 0.8272\n",
      "Epoch 25/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4711 - accuracy: 0.8642 - val_loss: 0.5776 - val_accuracy: 0.8286\n",
      "Epoch 26/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4604 - accuracy: 0.8670 - val_loss: 0.5653 - val_accuracy: 0.8336\n",
      "Epoch 27/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4505 - accuracy: 0.8704 - val_loss: 0.5592 - val_accuracy: 0.8342\n",
      "Epoch 28/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4405 - accuracy: 0.8720 - val_loss: 0.5544 - val_accuracy: 0.8368\n",
      "Epoch 29/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4319 - accuracy: 0.8742 - val_loss: 0.5472 - val_accuracy: 0.8400\n",
      "Epoch 30/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4225 - accuracy: 0.8760 - val_loss: 0.5429 - val_accuracy: 0.8410\n",
      "1032/1032 [==============================] - 2s 2ms/step\n",
      "[CV] END learning_rate=0.04556125739834199, n_hidden=1, n_units=173; total time= 1.5min\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_6 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 136)               106760    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 136)               18632     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 136)               18632     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 26)                3562      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 147586 (576.51 KB)\n",
      "Trainable params: 147586 (576.51 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 2.3011 - accuracy: 0.3832 - val_loss: 1.4671 - val_accuracy: 0.5728\n",
      "Epoch 2/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.2679 - accuracy: 0.6275 - val_loss: 1.1797 - val_accuracy: 0.6548\n",
      "Epoch 3/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.0453 - accuracy: 0.6949 - val_loss: 1.0238 - val_accuracy: 0.6984\n",
      "Epoch 4/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.9021 - accuracy: 0.7344 - val_loss: 0.8854 - val_accuracy: 0.7362\n",
      "Epoch 5/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.7942 - accuracy: 0.7654 - val_loss: 0.8180 - val_accuracy: 0.7570\n",
      "Epoch 6/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.7100 - accuracy: 0.7886 - val_loss: 0.7201 - val_accuracy: 0.7898\n",
      "Epoch 7/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.6436 - accuracy: 0.8082 - val_loss: 0.6926 - val_accuracy: 0.7978\n",
      "Epoch 8/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5914 - accuracy: 0.8225 - val_loss: 0.6535 - val_accuracy: 0.8036\n",
      "Epoch 9/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5458 - accuracy: 0.8345 - val_loss: 0.6060 - val_accuracy: 0.8178\n",
      "Epoch 10/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5058 - accuracy: 0.8480 - val_loss: 0.5798 - val_accuracy: 0.8264\n",
      "Epoch 11/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4743 - accuracy: 0.8564 - val_loss: 0.5668 - val_accuracy: 0.8302\n",
      "Epoch 12/30\n",
      "1032/1032 [==============================] - 4s 3ms/step - loss: 0.4471 - accuracy: 0.8644 - val_loss: 0.5402 - val_accuracy: 0.8394\n",
      "Epoch 13/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4220 - accuracy: 0.8711 - val_loss: 0.5271 - val_accuracy: 0.8356\n",
      "Epoch 14/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3995 - accuracy: 0.8750 - val_loss: 0.5169 - val_accuracy: 0.8468\n",
      "Epoch 15/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3799 - accuracy: 0.8817 - val_loss: 0.5076 - val_accuracy: 0.8434\n",
      "Epoch 16/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3617 - accuracy: 0.8876 - val_loss: 0.4870 - val_accuracy: 0.8528\n",
      "Epoch 17/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3447 - accuracy: 0.8919 - val_loss: 0.4771 - val_accuracy: 0.8524\n",
      "Epoch 18/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3311 - accuracy: 0.8965 - val_loss: 0.4700 - val_accuracy: 0.8572\n",
      "Epoch 19/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3174 - accuracy: 0.8999 - val_loss: 0.4807 - val_accuracy: 0.8538\n",
      "Epoch 20/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3041 - accuracy: 0.9034 - val_loss: 0.4730 - val_accuracy: 0.8540\n",
      "Epoch 21/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2924 - accuracy: 0.9072 - val_loss: 0.4679 - val_accuracy: 0.8550\n",
      "Epoch 22/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2811 - accuracy: 0.9100 - val_loss: 0.4623 - val_accuracy: 0.8592\n",
      "Epoch 23/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2688 - accuracy: 0.9142 - val_loss: 0.4597 - val_accuracy: 0.8614\n",
      "Epoch 24/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2609 - accuracy: 0.9167 - val_loss: 0.4486 - val_accuracy: 0.8638\n",
      "Epoch 25/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2507 - accuracy: 0.9196 - val_loss: 0.4415 - val_accuracy: 0.8650\n",
      "Epoch 26/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2416 - accuracy: 0.9227 - val_loss: 0.4720 - val_accuracy: 0.8592\n",
      "Epoch 27/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2329 - accuracy: 0.9244 - val_loss: 0.4530 - val_accuracy: 0.8610\n",
      "Epoch 28/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2250 - accuracy: 0.9269 - val_loss: 0.4456 - val_accuracy: 0.8670\n",
      "Epoch 29/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2174 - accuracy: 0.9295 - val_loss: 0.4456 - val_accuracy: 0.8668\n",
      "Epoch 30/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2107 - accuracy: 0.9314 - val_loss: 0.4549 - val_accuracy: 0.8670\n",
      "1032/1032 [==============================] - 2s 2ms/step\n",
      "[CV] END learning_rate=0.011526936914191117, n_hidden=3, n_units=136; total time= 1.6min\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_7 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 136)               106760    \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 136)               18632     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 136)               18632     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 26)                3562      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 147586 (576.51 KB)\n",
      "Trainable params: 147586 (576.51 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 2.3505 - accuracy: 0.3695 - val_loss: 1.4995 - val_accuracy: 0.5776\n",
      "Epoch 2/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.2575 - accuracy: 0.6325 - val_loss: 1.1357 - val_accuracy: 0.6730\n",
      "Epoch 3/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.0159 - accuracy: 0.7022 - val_loss: 0.9584 - val_accuracy: 0.7220\n",
      "Epoch 4/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.8757 - accuracy: 0.7437 - val_loss: 0.8459 - val_accuracy: 0.7546\n",
      "Epoch 5/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.7699 - accuracy: 0.7742 - val_loss: 0.7605 - val_accuracy: 0.7770\n",
      "Epoch 6/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.6892 - accuracy: 0.7970 - val_loss: 0.7175 - val_accuracy: 0.7890\n",
      "Epoch 7/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.6278 - accuracy: 0.8124 - val_loss: 0.6654 - val_accuracy: 0.8016\n",
      "Epoch 8/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5767 - accuracy: 0.8282 - val_loss: 0.6291 - val_accuracy: 0.8108\n",
      "Epoch 9/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5362 - accuracy: 0.8376 - val_loss: 0.6063 - val_accuracy: 0.8160\n",
      "Epoch 10/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5006 - accuracy: 0.8478 - val_loss: 0.5660 - val_accuracy: 0.8300\n",
      "Epoch 11/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4711 - accuracy: 0.8567 - val_loss: 0.5514 - val_accuracy: 0.8310\n",
      "Epoch 12/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4432 - accuracy: 0.8633 - val_loss: 0.5372 - val_accuracy: 0.8360\n",
      "Epoch 13/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4219 - accuracy: 0.8704 - val_loss: 0.5396 - val_accuracy: 0.8336\n",
      "Epoch 14/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3999 - accuracy: 0.8771 - val_loss: 0.5146 - val_accuracy: 0.8456\n",
      "Epoch 15/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3833 - accuracy: 0.8804 - val_loss: 0.5129 - val_accuracy: 0.8432\n",
      "Epoch 16/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3662 - accuracy: 0.8863 - val_loss: 0.4954 - val_accuracy: 0.8438\n",
      "Epoch 17/30\n",
      "1032/1032 [==============================] - 4s 3ms/step - loss: 0.3513 - accuracy: 0.8911 - val_loss: 0.4933 - val_accuracy: 0.8474\n",
      "Epoch 18/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3369 - accuracy: 0.8949 - val_loss: 0.4829 - val_accuracy: 0.8538\n",
      "Epoch 19/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3241 - accuracy: 0.8970 - val_loss: 0.4975 - val_accuracy: 0.8496\n",
      "Epoch 20/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3112 - accuracy: 0.9030 - val_loss: 0.4856 - val_accuracy: 0.8514\n",
      "Epoch 21/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.3003 - accuracy: 0.9058 - val_loss: 0.4767 - val_accuracy: 0.8554\n",
      "Epoch 22/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2889 - accuracy: 0.9081 - val_loss: 0.4660 - val_accuracy: 0.8594\n",
      "Epoch 23/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2785 - accuracy: 0.9112 - val_loss: 0.4680 - val_accuracy: 0.8562\n",
      "Epoch 24/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2684 - accuracy: 0.9138 - val_loss: 0.4669 - val_accuracy: 0.8540\n",
      "Epoch 25/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2599 - accuracy: 0.9169 - val_loss: 0.4672 - val_accuracy: 0.8562\n",
      "Epoch 26/30\n",
      "1032/1032 [==============================] - 4s 3ms/step - loss: 0.2515 - accuracy: 0.9185 - val_loss: 0.4508 - val_accuracy: 0.8618\n",
      "Epoch 27/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2426 - accuracy: 0.9227 - val_loss: 0.4562 - val_accuracy: 0.8608\n",
      "Epoch 28/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2340 - accuracy: 0.9253 - val_loss: 0.4585 - val_accuracy: 0.8602\n",
      "Epoch 29/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2278 - accuracy: 0.9260 - val_loss: 0.4547 - val_accuracy: 0.8618\n",
      "Epoch 30/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2193 - accuracy: 0.9281 - val_loss: 0.4699 - val_accuracy: 0.8572\n",
      "1032/1032 [==============================] - 2s 2ms/step\n",
      "[CV] END learning_rate=0.011526936914191117, n_hidden=3, n_units=136; total time= 1.7min\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_8 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 220)               172700    \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 220)               48620     \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 220)               48620     \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 26)                5746      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 275686 (1.05 MB)\n",
      "Trainable params: 275686 (1.05 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1032/1032 [==============================] - 4s 3ms/step - loss: 2.1665 - accuracy: 0.4140 - val_loss: 1.3830 - val_accuracy: 0.5972\n",
      "Epoch 2/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.1827 - accuracy: 0.6546 - val_loss: 1.0936 - val_accuracy: 0.6812\n",
      "Epoch 3/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.9613 - accuracy: 0.7190 - val_loss: 0.9518 - val_accuracy: 0.7220\n",
      "Epoch 4/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.8207 - accuracy: 0.7610 - val_loss: 0.8269 - val_accuracy: 0.7616\n",
      "Epoch 5/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.7162 - accuracy: 0.7912 - val_loss: 0.7559 - val_accuracy: 0.7760\n",
      "Epoch 6/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.6380 - accuracy: 0.8130 - val_loss: 0.6697 - val_accuracy: 0.8028\n",
      "Epoch 7/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5787 - accuracy: 0.8261 - val_loss: 0.6327 - val_accuracy: 0.8116\n",
      "Epoch 8/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.5317 - accuracy: 0.8415 - val_loss: 0.6021 - val_accuracy: 0.8196\n",
      "Epoch 9/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.4911 - accuracy: 0.8522 - val_loss: 0.5675 - val_accuracy: 0.8292\n",
      "Epoch 10/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.4570 - accuracy: 0.8617 - val_loss: 0.5424 - val_accuracy: 0.8374\n",
      "Epoch 11/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.4279 - accuracy: 0.8697 - val_loss: 0.5353 - val_accuracy: 0.8398\n",
      "Epoch 12/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.4041 - accuracy: 0.8745 - val_loss: 0.5096 - val_accuracy: 0.8416\n",
      "Epoch 13/30\n",
      "1032/1032 [==============================] - 5s 5ms/step - loss: 0.3802 - accuracy: 0.8824 - val_loss: 0.4965 - val_accuracy: 0.8432\n",
      "Epoch 14/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.3602 - accuracy: 0.8874 - val_loss: 0.4989 - val_accuracy: 0.8452\n",
      "Epoch 15/30\n",
      "1032/1032 [==============================] - 4s 3ms/step - loss: 0.3406 - accuracy: 0.8942 - val_loss: 0.4803 - val_accuracy: 0.8496\n",
      "Epoch 16/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.3239 - accuracy: 0.8992 - val_loss: 0.4637 - val_accuracy: 0.8566\n",
      "Epoch 17/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.3077 - accuracy: 0.9028 - val_loss: 0.4578 - val_accuracy: 0.8564\n",
      "Epoch 18/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2945 - accuracy: 0.9088 - val_loss: 0.4492 - val_accuracy: 0.8594\n",
      "Epoch 19/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2814 - accuracy: 0.9112 - val_loss: 0.4553 - val_accuracy: 0.8578\n",
      "Epoch 20/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2681 - accuracy: 0.9144 - val_loss: 0.4512 - val_accuracy: 0.8618\n",
      "Epoch 21/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.2564 - accuracy: 0.9194 - val_loss: 0.4433 - val_accuracy: 0.8620\n",
      "Epoch 22/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.2446 - accuracy: 0.9226 - val_loss: 0.4436 - val_accuracy: 0.8616\n",
      "Epoch 23/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2337 - accuracy: 0.9253 - val_loss: 0.4375 - val_accuracy: 0.8652\n",
      "Epoch 24/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2246 - accuracy: 0.9281 - val_loss: 0.4336 - val_accuracy: 0.8672\n",
      "Epoch 25/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.2159 - accuracy: 0.9316 - val_loss: 0.4310 - val_accuracy: 0.8690\n",
      "Epoch 26/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.2062 - accuracy: 0.9339 - val_loss: 0.4546 - val_accuracy: 0.8602\n",
      "Epoch 27/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.1974 - accuracy: 0.9356 - val_loss: 0.4347 - val_accuracy: 0.8694\n",
      "Epoch 28/30\n",
      "1032/1032 [==============================] - 4s 3ms/step - loss: 0.1902 - accuracy: 0.9390 - val_loss: 0.4416 - val_accuracy: 0.8668\n",
      "Epoch 29/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.1824 - accuracy: 0.9409 - val_loss: 0.4348 - val_accuracy: 0.8708\n",
      "Epoch 30/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.1757 - accuracy: 0.9435 - val_loss: 0.4358 - val_accuracy: 0.8716\n",
      "1032/1032 [==============================] - 2s 2ms/step\n",
      "[CV] END learning_rate=0.0051596519805228586, n_hidden=3, n_units=220; total time= 1.9min\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_9 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 220)               172700    \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 220)               48620     \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 220)               48620     \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 26)                5746      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 275686 (1.05 MB)\n",
      "Trainable params: 275686 (1.05 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1032/1032 [==============================] - 4s 3ms/step - loss: 2.1384 - accuracy: 0.4233 - val_loss: 1.3697 - val_accuracy: 0.6108\n",
      "Epoch 2/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.1766 - accuracy: 0.6554 - val_loss: 1.0771 - val_accuracy: 0.6908\n",
      "Epoch 3/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.9676 - accuracy: 0.7160 - val_loss: 0.9206 - val_accuracy: 0.7348\n",
      "Epoch 4/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.8313 - accuracy: 0.7562 - val_loss: 0.8099 - val_accuracy: 0.7616\n",
      "Epoch 5/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.7276 - accuracy: 0.7865 - val_loss: 0.7334 - val_accuracy: 0.7822\n",
      "Epoch 6/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.6508 - accuracy: 0.8056 - val_loss: 0.6794 - val_accuracy: 0.7986\n",
      "Epoch 7/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.5919 - accuracy: 0.8233 - val_loss: 0.6290 - val_accuracy: 0.8156\n",
      "Epoch 8/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.5426 - accuracy: 0.8372 - val_loss: 0.5919 - val_accuracy: 0.8208\n",
      "Epoch 9/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5025 - accuracy: 0.8480 - val_loss: 0.5698 - val_accuracy: 0.8276\n",
      "Epoch 10/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4676 - accuracy: 0.8579 - val_loss: 0.5317 - val_accuracy: 0.8342\n",
      "Epoch 11/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.4376 - accuracy: 0.8665 - val_loss: 0.5169 - val_accuracy: 0.8372\n",
      "Epoch 12/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.4104 - accuracy: 0.8733 - val_loss: 0.4993 - val_accuracy: 0.8496\n",
      "Epoch 13/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3880 - accuracy: 0.8817 - val_loss: 0.4973 - val_accuracy: 0.8472\n",
      "Epoch 14/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3659 - accuracy: 0.8869 - val_loss: 0.4741 - val_accuracy: 0.8520\n",
      "Epoch 15/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.3489 - accuracy: 0.8917 - val_loss: 0.4858 - val_accuracy: 0.8478\n",
      "Epoch 16/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.3316 - accuracy: 0.8970 - val_loss: 0.4654 - val_accuracy: 0.8560\n",
      "Epoch 17/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.3164 - accuracy: 0.9014 - val_loss: 0.4551 - val_accuracy: 0.8572\n",
      "Epoch 18/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3014 - accuracy: 0.9043 - val_loss: 0.4503 - val_accuracy: 0.8628\n",
      "Epoch 19/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2882 - accuracy: 0.9092 - val_loss: 0.4505 - val_accuracy: 0.8616\n",
      "Epoch 20/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.2754 - accuracy: 0.9129 - val_loss: 0.4525 - val_accuracy: 0.8596\n",
      "Epoch 21/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.2629 - accuracy: 0.9166 - val_loss: 0.4499 - val_accuracy: 0.8586\n",
      "Epoch 22/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2527 - accuracy: 0.9191 - val_loss: 0.4382 - val_accuracy: 0.8668\n",
      "Epoch 23/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2404 - accuracy: 0.9226 - val_loss: 0.4378 - val_accuracy: 0.8668\n",
      "Epoch 24/30\n",
      "1032/1032 [==============================] - 4s 3ms/step - loss: 0.2301 - accuracy: 0.9252 - val_loss: 0.4346 - val_accuracy: 0.8622\n",
      "Epoch 25/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.2221 - accuracy: 0.9280 - val_loss: 0.4381 - val_accuracy: 0.8702\n",
      "Epoch 26/30\n",
      "1032/1032 [==============================] - 4s 3ms/step - loss: 0.2120 - accuracy: 0.9308 - val_loss: 0.4246 - val_accuracy: 0.8708\n",
      "Epoch 27/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2039 - accuracy: 0.9338 - val_loss: 0.4308 - val_accuracy: 0.8684\n",
      "Epoch 28/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.1950 - accuracy: 0.9365 - val_loss: 0.4365 - val_accuracy: 0.8666\n",
      "Epoch 29/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.1877 - accuracy: 0.9390 - val_loss: 0.4266 - val_accuracy: 0.8718\n",
      "Epoch 30/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.1789 - accuracy: 0.9407 - val_loss: 0.4429 - val_accuracy: 0.8670\n",
      "1032/1032 [==============================] - 2s 2ms/step\n",
      "[CV] END learning_rate=0.0051596519805228586, n_hidden=3, n_units=220; total time= 1.9min\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_10 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 260)               204100    \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 260)               67860     \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 26)                6786      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 278746 (1.06 MB)\n",
      "Trainable params: 278746 (1.06 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 2.0550 - accuracy: 0.4718 - val_loss: 1.3576 - val_accuracy: 0.6158\n",
      "Epoch 2/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 1.1966 - accuracy: 0.6548 - val_loss: 1.1262 - val_accuracy: 0.6750\n",
      "Epoch 3/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 1.0230 - accuracy: 0.7041 - val_loss: 1.0183 - val_accuracy: 0.7062\n",
      "Epoch 4/30\n",
      "1032/1032 [==============================] - 4s 3ms/step - loss: 0.9079 - accuracy: 0.7385 - val_loss: 0.9078 - val_accuracy: 0.7396\n",
      "Epoch 5/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.8170 - accuracy: 0.7650 - val_loss: 0.8485 - val_accuracy: 0.7520\n",
      "Epoch 6/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.7416 - accuracy: 0.7859 - val_loss: 0.7649 - val_accuracy: 0.7740\n",
      "Epoch 7/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.6787 - accuracy: 0.8034 - val_loss: 0.7266 - val_accuracy: 0.7906\n",
      "Epoch 8/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.6270 - accuracy: 0.8177 - val_loss: 0.6867 - val_accuracy: 0.8000\n",
      "Epoch 9/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5822 - accuracy: 0.8303 - val_loss: 0.6435 - val_accuracy: 0.8126\n",
      "Epoch 10/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5432 - accuracy: 0.8406 - val_loss: 0.6173 - val_accuracy: 0.8186\n",
      "Epoch 11/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.5106 - accuracy: 0.8507 - val_loss: 0.5983 - val_accuracy: 0.8222\n",
      "Epoch 12/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.4829 - accuracy: 0.8575 - val_loss: 0.5721 - val_accuracy: 0.8298\n",
      "Epoch 13/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4572 - accuracy: 0.8656 - val_loss: 0.5529 - val_accuracy: 0.8356\n",
      "Epoch 14/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4344 - accuracy: 0.8698 - val_loss: 0.5396 - val_accuracy: 0.8412\n",
      "Epoch 15/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4139 - accuracy: 0.8774 - val_loss: 0.5215 - val_accuracy: 0.8452\n",
      "Epoch 16/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.3954 - accuracy: 0.8823 - val_loss: 0.5099 - val_accuracy: 0.8476\n",
      "Epoch 17/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.3785 - accuracy: 0.8861 - val_loss: 0.4960 - val_accuracy: 0.8522\n",
      "Epoch 18/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3636 - accuracy: 0.8920 - val_loss: 0.4888 - val_accuracy: 0.8480\n",
      "Epoch 19/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3496 - accuracy: 0.8947 - val_loss: 0.4829 - val_accuracy: 0.8554\n",
      "Epoch 20/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.3353 - accuracy: 0.8992 - val_loss: 0.4777 - val_accuracy: 0.8576\n",
      "Epoch 21/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.3237 - accuracy: 0.9032 - val_loss: 0.4717 - val_accuracy: 0.8604\n",
      "Epoch 22/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3116 - accuracy: 0.9075 - val_loss: 0.4628 - val_accuracy: 0.8620\n",
      "Epoch 23/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3006 - accuracy: 0.9104 - val_loss: 0.4566 - val_accuracy: 0.8634\n",
      "Epoch 24/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2907 - accuracy: 0.9121 - val_loss: 0.4551 - val_accuracy: 0.8664\n",
      "Epoch 25/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.2812 - accuracy: 0.9152 - val_loss: 0.4488 - val_accuracy: 0.8686\n",
      "Epoch 26/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.2718 - accuracy: 0.9194 - val_loss: 0.4531 - val_accuracy: 0.8634\n",
      "Epoch 27/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.2627 - accuracy: 0.9213 - val_loss: 0.4470 - val_accuracy: 0.8660\n",
      "Epoch 28/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2552 - accuracy: 0.9235 - val_loss: 0.4461 - val_accuracy: 0.8714\n",
      "Epoch 29/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.2469 - accuracy: 0.9263 - val_loss: 0.4400 - val_accuracy: 0.8698\n",
      "Epoch 30/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.2397 - accuracy: 0.9284 - val_loss: 0.4379 - val_accuracy: 0.8690\n",
      "1032/1032 [==============================] - 3s 3ms/step\n",
      "[CV] END learning_rate=0.0013146668015383907, n_hidden=2, n_units=260; total time= 1.9min\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_11 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 260)               204100    \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 260)               67860     \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 26)                6786      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 278746 (1.06 MB)\n",
      "Trainable params: 278746 (1.06 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 2.0455 - accuracy: 0.4652 - val_loss: 1.3815 - val_accuracy: 0.6118\n",
      "Epoch 2/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 1.2142 - accuracy: 0.6515 - val_loss: 1.1402 - val_accuracy: 0.6786\n",
      "Epoch 3/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 1.0382 - accuracy: 0.6988 - val_loss: 1.0157 - val_accuracy: 0.7136\n",
      "Epoch 4/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.9253 - accuracy: 0.7326 - val_loss: 0.9231 - val_accuracy: 0.7362\n",
      "Epoch 5/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.8354 - accuracy: 0.7588 - val_loss: 0.8493 - val_accuracy: 0.7574\n",
      "Epoch 6/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.7605 - accuracy: 0.7807 - val_loss: 0.7928 - val_accuracy: 0.7712\n",
      "Epoch 7/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.6983 - accuracy: 0.7985 - val_loss: 0.7443 - val_accuracy: 0.7836\n",
      "Epoch 8/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.6442 - accuracy: 0.8127 - val_loss: 0.6933 - val_accuracy: 0.7958\n",
      "Epoch 9/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.5996 - accuracy: 0.8265 - val_loss: 0.6646 - val_accuracy: 0.8022\n",
      "Epoch 10/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.5602 - accuracy: 0.8369 - val_loss: 0.6206 - val_accuracy: 0.8148\n",
      "Epoch 11/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.5261 - accuracy: 0.8468 - val_loss: 0.5951 - val_accuracy: 0.8178\n",
      "Epoch 12/30\n",
      "1032/1032 [==============================] - 4s 3ms/step - loss: 0.4953 - accuracy: 0.8552 - val_loss: 0.5736 - val_accuracy: 0.8240\n",
      "Epoch 13/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4699 - accuracy: 0.8620 - val_loss: 0.5629 - val_accuracy: 0.8280\n",
      "Epoch 14/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4453 - accuracy: 0.8690 - val_loss: 0.5436 - val_accuracy: 0.8376\n",
      "Epoch 15/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.4260 - accuracy: 0.8729 - val_loss: 0.5327 - val_accuracy: 0.8348\n",
      "Epoch 16/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.4065 - accuracy: 0.8796 - val_loss: 0.5139 - val_accuracy: 0.8412\n",
      "Epoch 17/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3887 - accuracy: 0.8835 - val_loss: 0.5035 - val_accuracy: 0.8454\n",
      "Epoch 18/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3733 - accuracy: 0.8886 - val_loss: 0.4927 - val_accuracy: 0.8484\n",
      "Epoch 19/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.3583 - accuracy: 0.8920 - val_loss: 0.4875 - val_accuracy: 0.8488\n",
      "Epoch 20/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.3446 - accuracy: 0.8971 - val_loss: 0.4827 - val_accuracy: 0.8518\n",
      "Epoch 21/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3325 - accuracy: 0.9004 - val_loss: 0.4712 - val_accuracy: 0.8524\n",
      "Epoch 22/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3202 - accuracy: 0.9040 - val_loss: 0.4657 - val_accuracy: 0.8582\n",
      "Epoch 23/30\n",
      "1032/1032 [==============================] - 4s 3ms/step - loss: 0.3084 - accuracy: 0.9059 - val_loss: 0.4618 - val_accuracy: 0.8592\n",
      "Epoch 24/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.2978 - accuracy: 0.9094 - val_loss: 0.4563 - val_accuracy: 0.8590\n",
      "Epoch 25/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.2885 - accuracy: 0.9124 - val_loss: 0.4501 - val_accuracy: 0.8618\n",
      "Epoch 26/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2791 - accuracy: 0.9143 - val_loss: 0.4416 - val_accuracy: 0.8612\n",
      "Epoch 27/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2703 - accuracy: 0.9174 - val_loss: 0.4436 - val_accuracy: 0.8650\n",
      "Epoch 28/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.2615 - accuracy: 0.9205 - val_loss: 0.4418 - val_accuracy: 0.8632\n",
      "Epoch 29/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.2545 - accuracy: 0.9227 - val_loss: 0.4366 - val_accuracy: 0.8642\n",
      "Epoch 30/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2454 - accuracy: 0.9241 - val_loss: 0.4452 - val_accuracy: 0.8652\n",
      "1032/1032 [==============================] - 2s 2ms/step\n",
      "[CV] END learning_rate=0.0013146668015383907, n_hidden=2, n_units=260; total time= 1.9min\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_12 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 159)               124815    \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 159)               25440     \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 159)               25440     \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 26)                4160      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 179855 (702.56 KB)\n",
      "Trainable params: 179855 (702.56 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 2.2659 - accuracy: 0.3941 - val_loss: 1.4266 - val_accuracy: 0.5942\n",
      "Epoch 2/30\n",
      "1032/1032 [==============================] - 4s 3ms/step - loss: 1.2344 - accuracy: 0.6390 - val_loss: 1.1422 - val_accuracy: 0.6698\n",
      "Epoch 3/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.0165 - accuracy: 0.7060 - val_loss: 0.9998 - val_accuracy: 0.7068\n",
      "Epoch 4/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.8745 - accuracy: 0.7462 - val_loss: 0.8603 - val_accuracy: 0.7532\n",
      "Epoch 5/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.7647 - accuracy: 0.7763 - val_loss: 0.7882 - val_accuracy: 0.7720\n",
      "Epoch 6/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.6787 - accuracy: 0.8003 - val_loss: 0.6966 - val_accuracy: 0.7942\n",
      "Epoch 7/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.6116 - accuracy: 0.8175 - val_loss: 0.6573 - val_accuracy: 0.8042\n",
      "Epoch 8/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5596 - accuracy: 0.8326 - val_loss: 0.6306 - val_accuracy: 0.8114\n",
      "Epoch 9/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5165 - accuracy: 0.8448 - val_loss: 0.5868 - val_accuracy: 0.8258\n",
      "Epoch 10/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4800 - accuracy: 0.8555 - val_loss: 0.5622 - val_accuracy: 0.8320\n",
      "Epoch 11/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.4490 - accuracy: 0.8638 - val_loss: 0.5502 - val_accuracy: 0.8320\n",
      "Epoch 12/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.4243 - accuracy: 0.8706 - val_loss: 0.5238 - val_accuracy: 0.8438\n",
      "Epoch 13/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4015 - accuracy: 0.8771 - val_loss: 0.5228 - val_accuracy: 0.8428\n",
      "Epoch 14/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3812 - accuracy: 0.8830 - val_loss: 0.5087 - val_accuracy: 0.8458\n",
      "Epoch 15/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3618 - accuracy: 0.8873 - val_loss: 0.4953 - val_accuracy: 0.8538\n",
      "Epoch 16/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.3453 - accuracy: 0.8929 - val_loss: 0.4772 - val_accuracy: 0.8580\n",
      "Epoch 17/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3288 - accuracy: 0.8978 - val_loss: 0.4795 - val_accuracy: 0.8558\n",
      "Epoch 18/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3163 - accuracy: 0.9028 - val_loss: 0.4669 - val_accuracy: 0.8616\n",
      "Epoch 19/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3034 - accuracy: 0.9051 - val_loss: 0.4785 - val_accuracy: 0.8554\n",
      "Epoch 20/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2905 - accuracy: 0.9081 - val_loss: 0.4664 - val_accuracy: 0.8602\n",
      "Epoch 21/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.2786 - accuracy: 0.9126 - val_loss: 0.4577 - val_accuracy: 0.8654\n",
      "Epoch 22/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2682 - accuracy: 0.9157 - val_loss: 0.4570 - val_accuracy: 0.8644\n",
      "Epoch 23/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2574 - accuracy: 0.9189 - val_loss: 0.4516 - val_accuracy: 0.8670\n",
      "Epoch 24/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2486 - accuracy: 0.9221 - val_loss: 0.4531 - val_accuracy: 0.8698\n",
      "Epoch 25/30\n",
      "1032/1032 [==============================] - 4s 3ms/step - loss: 0.2396 - accuracy: 0.9230 - val_loss: 0.4426 - val_accuracy: 0.8714\n",
      "Epoch 26/30\n",
      "1032/1032 [==============================] - 4s 3ms/step - loss: 0.2307 - accuracy: 0.9271 - val_loss: 0.4649 - val_accuracy: 0.8668\n",
      "Epoch 27/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2220 - accuracy: 0.9298 - val_loss: 0.4503 - val_accuracy: 0.8702\n",
      "Epoch 28/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2147 - accuracy: 0.9316 - val_loss: 0.4479 - val_accuracy: 0.8738\n",
      "Epoch 29/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2074 - accuracy: 0.9337 - val_loss: 0.4453 - val_accuracy: 0.8734\n",
      "Epoch 30/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.2002 - accuracy: 0.9351 - val_loss: 0.4495 - val_accuracy: 0.8716\n",
      "1032/1032 [==============================] - 2s 2ms/step\n",
      "[CV] END learning_rate=0.0053566460232582136, n_hidden=3, n_units=159; total time= 1.7min\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_13 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 159)               124815    \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 159)               25440     \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 159)               25440     \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 26)                4160      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 179855 (702.56 KB)\n",
      "Trainable params: 179855 (702.56 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1032/1032 [==============================] - 4s 3ms/step - loss: 2.3069 - accuracy: 0.3828 - val_loss: 1.4693 - val_accuracy: 0.5874\n",
      "Epoch 2/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.2573 - accuracy: 0.6329 - val_loss: 1.1539 - val_accuracy: 0.6676\n",
      "Epoch 3/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.0380 - accuracy: 0.6955 - val_loss: 0.9991 - val_accuracy: 0.7146\n",
      "Epoch 4/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.8990 - accuracy: 0.7345 - val_loss: 0.8805 - val_accuracy: 0.7414\n",
      "Epoch 5/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.7909 - accuracy: 0.7684 - val_loss: 0.7932 - val_accuracy: 0.7720\n",
      "Epoch 6/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.7061 - accuracy: 0.7917 - val_loss: 0.7381 - val_accuracy: 0.7812\n",
      "Epoch 7/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.6420 - accuracy: 0.8080 - val_loss: 0.6828 - val_accuracy: 0.7978\n",
      "Epoch 8/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.5891 - accuracy: 0.8241 - val_loss: 0.6380 - val_accuracy: 0.8038\n",
      "Epoch 9/30\n",
      "1032/1032 [==============================] - 4s 3ms/step - loss: 0.5445 - accuracy: 0.8348 - val_loss: 0.6238 - val_accuracy: 0.8126\n",
      "Epoch 10/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5079 - accuracy: 0.8460 - val_loss: 0.5795 - val_accuracy: 0.8206\n",
      "Epoch 11/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4777 - accuracy: 0.8550 - val_loss: 0.5506 - val_accuracy: 0.8292\n",
      "Epoch 12/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4480 - accuracy: 0.8624 - val_loss: 0.5399 - val_accuracy: 0.8396\n",
      "Epoch 13/30\n",
      "1032/1032 [==============================] - 4s 3ms/step - loss: 0.4260 - accuracy: 0.8693 - val_loss: 0.5308 - val_accuracy: 0.8376\n",
      "Epoch 14/30\n",
      "1032/1032 [==============================] - 4s 3ms/step - loss: 0.4025 - accuracy: 0.8760 - val_loss: 0.5099 - val_accuracy: 0.8460\n",
      "Epoch 15/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3853 - accuracy: 0.8799 - val_loss: 0.5187 - val_accuracy: 0.8408\n",
      "Epoch 16/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3679 - accuracy: 0.8859 - val_loss: 0.4905 - val_accuracy: 0.8448\n",
      "Epoch 17/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3524 - accuracy: 0.8913 - val_loss: 0.4892 - val_accuracy: 0.8474\n",
      "Epoch 18/30\n",
      "1032/1032 [==============================] - 4s 3ms/step - loss: 0.3378 - accuracy: 0.8932 - val_loss: 0.4733 - val_accuracy: 0.8588\n",
      "Epoch 19/30\n",
      "1032/1032 [==============================] - 4s 3ms/step - loss: 0.3241 - accuracy: 0.8974 - val_loss: 0.4769 - val_accuracy: 0.8568\n",
      "Epoch 20/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3112 - accuracy: 0.9034 - val_loss: 0.4733 - val_accuracy: 0.8526\n",
      "Epoch 21/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2998 - accuracy: 0.9055 - val_loss: 0.4682 - val_accuracy: 0.8602\n",
      "Epoch 22/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2892 - accuracy: 0.9084 - val_loss: 0.4533 - val_accuracy: 0.8598\n",
      "Epoch 23/30\n",
      "1032/1032 [==============================] - 4s 3ms/step - loss: 0.2772 - accuracy: 0.9117 - val_loss: 0.4641 - val_accuracy: 0.8600\n",
      "Epoch 24/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2667 - accuracy: 0.9144 - val_loss: 0.4550 - val_accuracy: 0.8584\n",
      "Epoch 25/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2576 - accuracy: 0.9172 - val_loss: 0.4595 - val_accuracy: 0.8632\n",
      "Epoch 26/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2480 - accuracy: 0.9200 - val_loss: 0.4407 - val_accuracy: 0.8682\n",
      "Epoch 27/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2396 - accuracy: 0.9224 - val_loss: 0.4454 - val_accuracy: 0.8612\n",
      "Epoch 28/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.2313 - accuracy: 0.9252 - val_loss: 0.4506 - val_accuracy: 0.8628\n",
      "Epoch 29/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2235 - accuracy: 0.9280 - val_loss: 0.4475 - val_accuracy: 0.8664\n",
      "Epoch 30/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2155 - accuracy: 0.9290 - val_loss: 0.4547 - val_accuracy: 0.8658\n",
      "1032/1032 [==============================] - 2s 2ms/step\n",
      "[CV] END learning_rate=0.0053566460232582136, n_hidden=3, n_units=159; total time= 1.7min\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_14 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 112)               87920     \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 112)               12656     \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 26)                2938      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 103514 (404.35 KB)\n",
      "Trainable params: 103514 (404.35 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1032/1032 [==============================] - 4s 3ms/step - loss: 2.2627 - accuracy: 0.3978 - val_loss: 1.4696 - val_accuracy: 0.5832\n",
      "Epoch 2/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.2876 - accuracy: 0.6224 - val_loss: 1.1966 - val_accuracy: 0.6538\n",
      "Epoch 3/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.0969 - accuracy: 0.6802 - val_loss: 1.0771 - val_accuracy: 0.6882\n",
      "Epoch 4/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.9832 - accuracy: 0.7141 - val_loss: 0.9704 - val_accuracy: 0.7230\n",
      "Epoch 5/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.8967 - accuracy: 0.7389 - val_loss: 0.9219 - val_accuracy: 0.7316\n",
      "Epoch 6/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.8231 - accuracy: 0.7608 - val_loss: 0.8334 - val_accuracy: 0.7614\n",
      "Epoch 7/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.7605 - accuracy: 0.7780 - val_loss: 0.8002 - val_accuracy: 0.7690\n",
      "Epoch 8/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.7067 - accuracy: 0.7931 - val_loss: 0.7477 - val_accuracy: 0.7838\n",
      "Epoch 9/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.6602 - accuracy: 0.8048 - val_loss: 0.7066 - val_accuracy: 0.7972\n",
      "Epoch 10/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.6185 - accuracy: 0.8177 - val_loss: 0.6747 - val_accuracy: 0.8046\n",
      "Epoch 11/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5840 - accuracy: 0.8273 - val_loss: 0.6531 - val_accuracy: 0.8084\n",
      "Epoch 12/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5548 - accuracy: 0.8359 - val_loss: 0.6254 - val_accuracy: 0.8160\n",
      "Epoch 13/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5284 - accuracy: 0.8421 - val_loss: 0.6036 - val_accuracy: 0.8246\n",
      "Epoch 14/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5047 - accuracy: 0.8484 - val_loss: 0.5905 - val_accuracy: 0.8252\n",
      "Epoch 15/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4834 - accuracy: 0.8560 - val_loss: 0.5743 - val_accuracy: 0.8344\n",
      "Epoch 16/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4644 - accuracy: 0.8607 - val_loss: 0.5561 - val_accuracy: 0.8382\n",
      "Epoch 17/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4468 - accuracy: 0.8660 - val_loss: 0.5454 - val_accuracy: 0.8410\n",
      "Epoch 18/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4321 - accuracy: 0.8703 - val_loss: 0.5379 - val_accuracy: 0.8448\n",
      "Epoch 19/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4172 - accuracy: 0.8747 - val_loss: 0.5293 - val_accuracy: 0.8420\n",
      "Epoch 20/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4040 - accuracy: 0.8786 - val_loss: 0.5208 - val_accuracy: 0.8478\n",
      "Epoch 21/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3918 - accuracy: 0.8818 - val_loss: 0.5154 - val_accuracy: 0.8464\n",
      "Epoch 22/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3795 - accuracy: 0.8846 - val_loss: 0.5000 - val_accuracy: 0.8516\n",
      "Epoch 23/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3673 - accuracy: 0.8891 - val_loss: 0.4997 - val_accuracy: 0.8520\n",
      "Epoch 24/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3576 - accuracy: 0.8915 - val_loss: 0.4927 - val_accuracy: 0.8570\n",
      "Epoch 25/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3483 - accuracy: 0.8929 - val_loss: 0.4882 - val_accuracy: 0.8596\n",
      "Epoch 26/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3386 - accuracy: 0.8974 - val_loss: 0.4970 - val_accuracy: 0.8508\n",
      "Epoch 27/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3299 - accuracy: 0.8979 - val_loss: 0.4837 - val_accuracy: 0.8612\n",
      "Epoch 28/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3221 - accuracy: 0.9026 - val_loss: 0.4781 - val_accuracy: 0.8652\n",
      "Epoch 29/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3140 - accuracy: 0.9028 - val_loss: 0.4762 - val_accuracy: 0.8594\n",
      "Epoch 30/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3067 - accuracy: 0.9073 - val_loss: 0.4679 - val_accuracy: 0.8672\n",
      "1032/1032 [==============================] - 2s 2ms/step\n",
      "[CV] END learning_rate=0.0053566460232582136, n_hidden=2, n_units=112; total time= 1.5min\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_15 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 112)               87920     \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 112)               12656     \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 26)                2938      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 103514 (404.35 KB)\n",
      "Trainable params: 103514 (404.35 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1032/1032 [==============================] - 4s 3ms/step - loss: 2.2697 - accuracy: 0.3956 - val_loss: 1.5082 - val_accuracy: 0.5762\n",
      "Epoch 2/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.2993 - accuracy: 0.6243 - val_loss: 1.1998 - val_accuracy: 0.6500\n",
      "Epoch 3/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.0971 - accuracy: 0.6815 - val_loss: 1.0641 - val_accuracy: 0.6922\n",
      "Epoch 4/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.9818 - accuracy: 0.7145 - val_loss: 0.9699 - val_accuracy: 0.7216\n",
      "Epoch 5/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.8908 - accuracy: 0.7415 - val_loss: 0.8932 - val_accuracy: 0.7466\n",
      "Epoch 6/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.8158 - accuracy: 0.7630 - val_loss: 0.8400 - val_accuracy: 0.7540\n",
      "Epoch 7/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.7528 - accuracy: 0.7808 - val_loss: 0.7880 - val_accuracy: 0.7712\n",
      "Epoch 8/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.6978 - accuracy: 0.7939 - val_loss: 0.7365 - val_accuracy: 0.7800\n",
      "Epoch 9/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.6529 - accuracy: 0.8078 - val_loss: 0.7063 - val_accuracy: 0.7944\n",
      "Epoch 10/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.6138 - accuracy: 0.8203 - val_loss: 0.6608 - val_accuracy: 0.8098\n",
      "Epoch 11/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5804 - accuracy: 0.8291 - val_loss: 0.6414 - val_accuracy: 0.8064\n",
      "Epoch 12/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5499 - accuracy: 0.8367 - val_loss: 0.6168 - val_accuracy: 0.8218\n",
      "Epoch 13/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5249 - accuracy: 0.8422 - val_loss: 0.6040 - val_accuracy: 0.8220\n",
      "Epoch 14/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5001 - accuracy: 0.8489 - val_loss: 0.5847 - val_accuracy: 0.8288\n",
      "Epoch 15/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4806 - accuracy: 0.8567 - val_loss: 0.5747 - val_accuracy: 0.8272\n",
      "Epoch 16/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4623 - accuracy: 0.8636 - val_loss: 0.5565 - val_accuracy: 0.8340\n",
      "Epoch 17/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4447 - accuracy: 0.8651 - val_loss: 0.5409 - val_accuracy: 0.8414\n",
      "Epoch 18/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4298 - accuracy: 0.8703 - val_loss: 0.5331 - val_accuracy: 0.8430\n",
      "Epoch 19/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4152 - accuracy: 0.8748 - val_loss: 0.5246 - val_accuracy: 0.8440\n",
      "Epoch 20/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4013 - accuracy: 0.8791 - val_loss: 0.5217 - val_accuracy: 0.8442\n",
      "Epoch 21/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3892 - accuracy: 0.8810 - val_loss: 0.5145 - val_accuracy: 0.8486\n",
      "Epoch 22/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3777 - accuracy: 0.8859 - val_loss: 0.5019 - val_accuracy: 0.8502\n",
      "Epoch 23/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3661 - accuracy: 0.8880 - val_loss: 0.5017 - val_accuracy: 0.8538\n",
      "Epoch 24/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3565 - accuracy: 0.8916 - val_loss: 0.4868 - val_accuracy: 0.8518\n",
      "Epoch 25/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3467 - accuracy: 0.8944 - val_loss: 0.4879 - val_accuracy: 0.8554\n",
      "Epoch 26/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3372 - accuracy: 0.8959 - val_loss: 0.4799 - val_accuracy: 0.8568\n",
      "Epoch 27/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3293 - accuracy: 0.8991 - val_loss: 0.4754 - val_accuracy: 0.8580\n",
      "Epoch 28/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3203 - accuracy: 0.9005 - val_loss: 0.4745 - val_accuracy: 0.8570\n",
      "Epoch 29/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3139 - accuracy: 0.9035 - val_loss: 0.4732 - val_accuracy: 0.8588\n",
      "Epoch 30/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3049 - accuracy: 0.9050 - val_loss: 0.4774 - val_accuracy: 0.8600\n",
      "1032/1032 [==============================] - 2s 2ms/step\n",
      "[CV] END learning_rate=0.0053566460232582136, n_hidden=2, n_units=112; total time= 1.5min\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_16 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 199)               156215    \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 199)               39800     \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 199)               39800     \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 26)                5200      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 241015 (941.46 KB)\n",
      "Trainable params: 241015 (941.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1032/1032 [==============================] - 4s 3ms/step - loss: 2.1328 - accuracy: 0.4261 - val_loss: 1.3601 - val_accuracy: 0.6114\n",
      "Epoch 2/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.1772 - accuracy: 0.6538 - val_loss: 1.0998 - val_accuracy: 0.6818\n",
      "Epoch 3/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.9630 - accuracy: 0.7193 - val_loss: 0.9458 - val_accuracy: 0.7236\n",
      "Epoch 4/30\n",
      "1032/1032 [==============================] - 4s 3ms/step - loss: 0.8197 - accuracy: 0.7618 - val_loss: 0.8183 - val_accuracy: 0.7628\n",
      "Epoch 5/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.7148 - accuracy: 0.7910 - val_loss: 0.7573 - val_accuracy: 0.7732\n",
      "Epoch 6/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.6375 - accuracy: 0.8124 - val_loss: 0.6712 - val_accuracy: 0.7992\n",
      "Epoch 7/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5793 - accuracy: 0.8268 - val_loss: 0.6380 - val_accuracy: 0.8104\n",
      "Epoch 8/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.5334 - accuracy: 0.8413 - val_loss: 0.6069 - val_accuracy: 0.8178\n",
      "Epoch 9/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.4947 - accuracy: 0.8497 - val_loss: 0.5701 - val_accuracy: 0.8274\n",
      "Epoch 10/30\n",
      "1032/1032 [==============================] - 4s 3ms/step - loss: 0.4609 - accuracy: 0.8604 - val_loss: 0.5530 - val_accuracy: 0.8324\n",
      "Epoch 11/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4334 - accuracy: 0.8682 - val_loss: 0.5446 - val_accuracy: 0.8316\n",
      "Epoch 12/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4097 - accuracy: 0.8745 - val_loss: 0.5180 - val_accuracy: 0.8410\n",
      "Epoch 13/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.3866 - accuracy: 0.8809 - val_loss: 0.5095 - val_accuracy: 0.8430\n",
      "Epoch 14/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.3674 - accuracy: 0.8865 - val_loss: 0.4957 - val_accuracy: 0.8510\n",
      "Epoch 15/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3485 - accuracy: 0.8930 - val_loss: 0.4844 - val_accuracy: 0.8498\n",
      "Epoch 16/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3319 - accuracy: 0.8977 - val_loss: 0.4733 - val_accuracy: 0.8584\n",
      "Epoch 17/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.3154 - accuracy: 0.9004 - val_loss: 0.4694 - val_accuracy: 0.8546\n",
      "Epoch 18/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.3026 - accuracy: 0.9052 - val_loss: 0.4555 - val_accuracy: 0.8644\n",
      "Epoch 19/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2896 - accuracy: 0.9099 - val_loss: 0.4664 - val_accuracy: 0.8584\n",
      "Epoch 20/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2767 - accuracy: 0.9131 - val_loss: 0.4563 - val_accuracy: 0.8622\n",
      "Epoch 21/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2658 - accuracy: 0.9157 - val_loss: 0.4501 - val_accuracy: 0.8650\n",
      "Epoch 22/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.2539 - accuracy: 0.9194 - val_loss: 0.4600 - val_accuracy: 0.8614\n",
      "Epoch 23/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.2443 - accuracy: 0.9227 - val_loss: 0.4353 - val_accuracy: 0.8664\n",
      "Epoch 24/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2334 - accuracy: 0.9263 - val_loss: 0.4377 - val_accuracy: 0.8708\n",
      "Epoch 25/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2251 - accuracy: 0.9289 - val_loss: 0.4379 - val_accuracy: 0.8718\n",
      "Epoch 26/30\n",
      "1032/1032 [==============================] - 4s 3ms/step - loss: 0.2152 - accuracy: 0.9316 - val_loss: 0.4730 - val_accuracy: 0.8576\n",
      "Epoch 27/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.2069 - accuracy: 0.9339 - val_loss: 0.4405 - val_accuracy: 0.8656\n",
      "Epoch 28/30\n",
      "1032/1032 [==============================] - 4s 3ms/step - loss: 0.1997 - accuracy: 0.9361 - val_loss: 0.4377 - val_accuracy: 0.8712\n",
      "Epoch 29/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.1917 - accuracy: 0.9380 - val_loss: 0.4334 - val_accuracy: 0.8740\n",
      "Epoch 30/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.1843 - accuracy: 0.9410 - val_loss: 0.4318 - val_accuracy: 0.8708\n",
      "1032/1032 [==============================] - 3s 2ms/step\n",
      "[CV] END learning_rate=0.025772086904282048, n_hidden=3, n_units=199; total time= 1.9min\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_17 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 199)               156215    \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 199)               39800     \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 199)               39800     \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 26)                5200      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 241015 (941.46 KB)\n",
      "Trainable params: 241015 (941.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1032/1032 [==============================] - 5s 4ms/step - loss: 2.1573 - accuracy: 0.4111 - val_loss: 1.3766 - val_accuracy: 0.6104\n",
      "Epoch 2/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.1846 - accuracy: 0.6534 - val_loss: 1.0989 - val_accuracy: 0.6776\n",
      "Epoch 3/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.9747 - accuracy: 0.7120 - val_loss: 0.9312 - val_accuracy: 0.7274\n",
      "Epoch 4/30\n",
      "1032/1032 [==============================] - 4s 3ms/step - loss: 0.8364 - accuracy: 0.7526 - val_loss: 0.8208 - val_accuracy: 0.7576\n",
      "Epoch 5/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.7295 - accuracy: 0.7853 - val_loss: 0.7438 - val_accuracy: 0.7774\n",
      "Epoch 6/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.6485 - accuracy: 0.8070 - val_loss: 0.6874 - val_accuracy: 0.7960\n",
      "Epoch 7/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5877 - accuracy: 0.8243 - val_loss: 0.6427 - val_accuracy: 0.8080\n",
      "Epoch 8/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5384 - accuracy: 0.8377 - val_loss: 0.6059 - val_accuracy: 0.8140\n",
      "Epoch 9/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.4985 - accuracy: 0.8498 - val_loss: 0.5886 - val_accuracy: 0.8194\n",
      "Epoch 10/30\n",
      "1032/1032 [==============================] - 4s 3ms/step - loss: 0.4641 - accuracy: 0.8582 - val_loss: 0.5433 - val_accuracy: 0.8334\n",
      "Epoch 11/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4354 - accuracy: 0.8666 - val_loss: 0.5320 - val_accuracy: 0.8300\n",
      "Epoch 12/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4085 - accuracy: 0.8743 - val_loss: 0.5165 - val_accuracy: 0.8442\n",
      "Epoch 13/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3868 - accuracy: 0.8803 - val_loss: 0.5152 - val_accuracy: 0.8436\n",
      "Epoch 14/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.3652 - accuracy: 0.8875 - val_loss: 0.4865 - val_accuracy: 0.8504\n",
      "Epoch 15/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3496 - accuracy: 0.8898 - val_loss: 0.5151 - val_accuracy: 0.8454\n",
      "Epoch 16/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3331 - accuracy: 0.8965 - val_loss: 0.4776 - val_accuracy: 0.8506\n",
      "Epoch 17/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3185 - accuracy: 0.9002 - val_loss: 0.4694 - val_accuracy: 0.8562\n",
      "Epoch 18/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.3031 - accuracy: 0.9041 - val_loss: 0.4687 - val_accuracy: 0.8588\n",
      "Epoch 19/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.2916 - accuracy: 0.9075 - val_loss: 0.4734 - val_accuracy: 0.8596\n",
      "Epoch 20/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2787 - accuracy: 0.9134 - val_loss: 0.4612 - val_accuracy: 0.8582\n",
      "Epoch 21/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.2677 - accuracy: 0.9144 - val_loss: 0.4619 - val_accuracy: 0.8578\n",
      "Epoch 22/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.2574 - accuracy: 0.9177 - val_loss: 0.4512 - val_accuracy: 0.8662\n",
      "Epoch 23/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.2461 - accuracy: 0.9213 - val_loss: 0.4529 - val_accuracy: 0.8638\n",
      "Epoch 24/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2363 - accuracy: 0.9237 - val_loss: 0.4452 - val_accuracy: 0.8644\n",
      "Epoch 25/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2278 - accuracy: 0.9256 - val_loss: 0.4476 - val_accuracy: 0.8684\n",
      "Epoch 26/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2187 - accuracy: 0.9292 - val_loss: 0.4390 - val_accuracy: 0.8654\n",
      "Epoch 27/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.2102 - accuracy: 0.9317 - val_loss: 0.4473 - val_accuracy: 0.8654\n",
      "Epoch 28/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.2017 - accuracy: 0.9360 - val_loss: 0.4471 - val_accuracy: 0.8694\n",
      "Epoch 29/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.1959 - accuracy: 0.9353 - val_loss: 0.4426 - val_accuracy: 0.8680\n",
      "Epoch 30/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.1879 - accuracy: 0.9390 - val_loss: 0.4541 - val_accuracy: 0.8640\n",
      "1032/1032 [==============================] - 2s 2ms/step\n",
      "[CV] END learning_rate=0.025772086904282048, n_hidden=3, n_units=199; total time= 1.8min\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_18 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 96)                75360     \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 96)                9312      \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 96)                9312      \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 26)                2522      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 96506 (376.98 KB)\n",
      "Trainable params: 96506 (376.98 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1032/1032 [==============================] - 4s 3ms/step - loss: 2.4047 - accuracy: 0.3508 - val_loss: 1.5227 - val_accuracy: 0.5722\n",
      "Epoch 2/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.2938 - accuracy: 0.6185 - val_loss: 1.1811 - val_accuracy: 0.6580\n",
      "Epoch 3/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.0568 - accuracy: 0.6903 - val_loss: 1.0213 - val_accuracy: 0.7024\n",
      "Epoch 4/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.9097 - accuracy: 0.7323 - val_loss: 0.8965 - val_accuracy: 0.7396\n",
      "Epoch 5/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.7990 - accuracy: 0.7633 - val_loss: 0.8090 - val_accuracy: 0.7592\n",
      "Epoch 6/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.7147 - accuracy: 0.7847 - val_loss: 0.7200 - val_accuracy: 0.7886\n",
      "Epoch 7/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.6497 - accuracy: 0.8052 - val_loss: 0.6871 - val_accuracy: 0.8026\n",
      "Epoch 8/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5985 - accuracy: 0.8207 - val_loss: 0.6506 - val_accuracy: 0.8052\n",
      "Epoch 9/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5567 - accuracy: 0.8310 - val_loss: 0.6090 - val_accuracy: 0.8178\n",
      "Epoch 10/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5205 - accuracy: 0.8429 - val_loss: 0.5846 - val_accuracy: 0.8210\n",
      "Epoch 11/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4913 - accuracy: 0.8507 - val_loss: 0.5795 - val_accuracy: 0.8238\n",
      "Epoch 12/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4669 - accuracy: 0.8565 - val_loss: 0.5428 - val_accuracy: 0.8324\n",
      "Epoch 13/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4436 - accuracy: 0.8631 - val_loss: 0.5501 - val_accuracy: 0.8348\n",
      "Epoch 14/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4240 - accuracy: 0.8699 - val_loss: 0.5290 - val_accuracy: 0.8410\n",
      "Epoch 15/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4058 - accuracy: 0.8743 - val_loss: 0.5172 - val_accuracy: 0.8426\n",
      "Epoch 16/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3877 - accuracy: 0.8796 - val_loss: 0.5060 - val_accuracy: 0.8510\n",
      "Epoch 17/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3719 - accuracy: 0.8839 - val_loss: 0.5023 - val_accuracy: 0.8508\n",
      "Epoch 18/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3601 - accuracy: 0.8885 - val_loss: 0.4940 - val_accuracy: 0.8510\n",
      "Epoch 19/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3463 - accuracy: 0.8916 - val_loss: 0.4945 - val_accuracy: 0.8524\n",
      "Epoch 20/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3343 - accuracy: 0.8939 - val_loss: 0.4927 - val_accuracy: 0.8542\n",
      "Epoch 21/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3222 - accuracy: 0.8985 - val_loss: 0.4875 - val_accuracy: 0.8550\n",
      "Epoch 22/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3118 - accuracy: 0.9015 - val_loss: 0.4808 - val_accuracy: 0.8516\n",
      "Epoch 23/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3021 - accuracy: 0.9054 - val_loss: 0.4871 - val_accuracy: 0.8576\n",
      "Epoch 24/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2924 - accuracy: 0.9067 - val_loss: 0.4758 - val_accuracy: 0.8604\n",
      "Epoch 25/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2844 - accuracy: 0.9095 - val_loss: 0.4714 - val_accuracy: 0.8642\n",
      "Epoch 26/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2745 - accuracy: 0.9123 - val_loss: 0.4948 - val_accuracy: 0.8558\n",
      "Epoch 27/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2656 - accuracy: 0.9146 - val_loss: 0.4773 - val_accuracy: 0.8578\n",
      "Epoch 28/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2593 - accuracy: 0.9167 - val_loss: 0.4880 - val_accuracy: 0.8576\n",
      "Epoch 29/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2519 - accuracy: 0.9189 - val_loss: 0.4662 - val_accuracy: 0.8670\n",
      "Epoch 30/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2451 - accuracy: 0.9212 - val_loss: 0.4699 - val_accuracy: 0.8666\n",
      "1032/1032 [==============================] - 2s 2ms/step\n",
      "[CV] END learning_rate=0.0021232215683280207, n_hidden=3, n_units=96; total time= 1.5min\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_19 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 96)                75360     \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 96)                9312      \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 96)                9312      \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 26)                2522      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 96506 (376.98 KB)\n",
      "Trainable params: 96506 (376.98 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1032/1032 [==============================] - 4s 3ms/step - loss: 2.4415 - accuracy: 0.3390 - val_loss: 1.5707 - val_accuracy: 0.5522\n",
      "Epoch 2/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.3207 - accuracy: 0.6137 - val_loss: 1.2023 - val_accuracy: 0.6442\n",
      "Epoch 3/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.0810 - accuracy: 0.6795 - val_loss: 1.0378 - val_accuracy: 0.6936\n",
      "Epoch 4/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.9379 - accuracy: 0.7234 - val_loss: 0.9176 - val_accuracy: 0.7236\n",
      "Epoch 5/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.8300 - accuracy: 0.7558 - val_loss: 0.8270 - val_accuracy: 0.7564\n",
      "Epoch 6/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.7496 - accuracy: 0.7772 - val_loss: 0.7790 - val_accuracy: 0.7692\n",
      "Epoch 7/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.6876 - accuracy: 0.7973 - val_loss: 0.7163 - val_accuracy: 0.7916\n",
      "Epoch 8/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.6350 - accuracy: 0.8112 - val_loss: 0.6796 - val_accuracy: 0.7956\n",
      "Epoch 9/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5945 - accuracy: 0.8224 - val_loss: 0.6591 - val_accuracy: 0.8048\n",
      "Epoch 10/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5586 - accuracy: 0.8320 - val_loss: 0.6171 - val_accuracy: 0.8184\n",
      "Epoch 11/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5296 - accuracy: 0.8405 - val_loss: 0.5855 - val_accuracy: 0.8232\n",
      "Epoch 12/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5007 - accuracy: 0.8470 - val_loss: 0.5778 - val_accuracy: 0.8274\n",
      "Epoch 13/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4797 - accuracy: 0.8543 - val_loss: 0.5732 - val_accuracy: 0.8274\n",
      "Epoch 14/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4563 - accuracy: 0.8603 - val_loss: 0.5516 - val_accuracy: 0.8338\n",
      "Epoch 15/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4398 - accuracy: 0.8640 - val_loss: 0.5621 - val_accuracy: 0.8334\n",
      "Epoch 16/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4214 - accuracy: 0.8708 - val_loss: 0.5225 - val_accuracy: 0.8438\n",
      "Epoch 17/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4054 - accuracy: 0.8745 - val_loss: 0.5243 - val_accuracy: 0.8464\n",
      "Epoch 18/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3910 - accuracy: 0.8793 - val_loss: 0.5019 - val_accuracy: 0.8512\n",
      "Epoch 19/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3771 - accuracy: 0.8844 - val_loss: 0.5322 - val_accuracy: 0.8440\n",
      "Epoch 20/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3630 - accuracy: 0.8883 - val_loss: 0.5151 - val_accuracy: 0.8436\n",
      "Epoch 21/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3516 - accuracy: 0.8908 - val_loss: 0.5118 - val_accuracy: 0.8480\n",
      "Epoch 22/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3399 - accuracy: 0.8935 - val_loss: 0.4931 - val_accuracy: 0.8508\n",
      "Epoch 23/30\n",
      "1032/1032 [==============================] - 4s 3ms/step - loss: 0.3276 - accuracy: 0.8972 - val_loss: 0.4944 - val_accuracy: 0.8510\n",
      "Epoch 24/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3178 - accuracy: 0.9006 - val_loss: 0.4780 - val_accuracy: 0.8570\n",
      "Epoch 25/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3084 - accuracy: 0.9024 - val_loss: 0.4843 - val_accuracy: 0.8522\n",
      "Epoch 26/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2999 - accuracy: 0.9041 - val_loss: 0.4745 - val_accuracy: 0.8560\n",
      "Epoch 27/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2905 - accuracy: 0.9080 - val_loss: 0.4787 - val_accuracy: 0.8566\n",
      "Epoch 28/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2807 - accuracy: 0.9120 - val_loss: 0.4718 - val_accuracy: 0.8582\n",
      "Epoch 29/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2738 - accuracy: 0.9134 - val_loss: 0.4702 - val_accuracy: 0.8610\n",
      "Epoch 30/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2647 - accuracy: 0.9147 - val_loss: 0.4741 - val_accuracy: 0.8582\n",
      "1032/1032 [==============================] - 2s 2ms/step\n",
      "[CV] END learning_rate=0.0021232215683280207, n_hidden=3, n_units=96; total time= 1.5min\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_20 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 26)                20410     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20410 (79.73 KB)\n",
      "Trainable params: 20410 (79.73 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1032/1032 [==============================] - 3s 2ms/step - loss: 2.2106 - accuracy: 0.4496 - val_loss: 1.6993 - val_accuracy: 0.5672\n",
      "Epoch 2/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.5429 - accuracy: 0.5925 - val_loss: 1.4583 - val_accuracy: 0.6030\n",
      "Epoch 3/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.3826 - accuracy: 0.6194 - val_loss: 1.3595 - val_accuracy: 0.6238\n",
      "Epoch 4/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.3031 - accuracy: 0.6354 - val_loss: 1.3028 - val_accuracy: 0.6316\n",
      "Epoch 5/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.2533 - accuracy: 0.6475 - val_loss: 1.2666 - val_accuracy: 0.6450\n",
      "Epoch 6/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.2178 - accuracy: 0.6576 - val_loss: 1.2362 - val_accuracy: 0.6542\n",
      "Epoch 7/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.1911 - accuracy: 0.6645 - val_loss: 1.2162 - val_accuracy: 0.6606\n",
      "Epoch 8/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.1701 - accuracy: 0.6712 - val_loss: 1.2008 - val_accuracy: 0.6614\n",
      "Epoch 9/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.1529 - accuracy: 0.6756 - val_loss: 1.1861 - val_accuracy: 0.6662\n",
      "Epoch 10/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.1381 - accuracy: 0.6806 - val_loss: 1.1740 - val_accuracy: 0.6712\n",
      "Epoch 11/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.1256 - accuracy: 0.6836 - val_loss: 1.1657 - val_accuracy: 0.6696\n",
      "Epoch 12/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.1154 - accuracy: 0.6869 - val_loss: 1.1556 - val_accuracy: 0.6736\n",
      "Epoch 13/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.1058 - accuracy: 0.6881 - val_loss: 1.1489 - val_accuracy: 0.6762\n",
      "Epoch 14/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0972 - accuracy: 0.6900 - val_loss: 1.1439 - val_accuracy: 0.6798\n",
      "Epoch 15/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.0899 - accuracy: 0.6924 - val_loss: 1.1380 - val_accuracy: 0.6806\n",
      "Epoch 16/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0831 - accuracy: 0.6942 - val_loss: 1.1322 - val_accuracy: 0.6832\n",
      "Epoch 17/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.0771 - accuracy: 0.6962 - val_loss: 1.1277 - val_accuracy: 0.6814\n",
      "Epoch 18/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.0711 - accuracy: 0.6987 - val_loss: 1.1233 - val_accuracy: 0.6840\n",
      "Epoch 19/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0663 - accuracy: 0.7001 - val_loss: 1.1211 - val_accuracy: 0.6830\n",
      "Epoch 20/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0615 - accuracy: 0.7004 - val_loss: 1.1172 - val_accuracy: 0.6848\n",
      "Epoch 21/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0571 - accuracy: 0.7025 - val_loss: 1.1140 - val_accuracy: 0.6882\n",
      "Epoch 22/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0529 - accuracy: 0.7028 - val_loss: 1.1112 - val_accuracy: 0.6854\n",
      "Epoch 23/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0486 - accuracy: 0.7050 - val_loss: 1.1087 - val_accuracy: 0.6912\n",
      "Epoch 24/30\n",
      "1032/1032 [==============================] - 3s 2ms/step - loss: 1.0452 - accuracy: 0.7060 - val_loss: 1.1064 - val_accuracy: 0.6908\n",
      "Epoch 25/30\n",
      "1032/1032 [==============================] - 3s 2ms/step - loss: 1.0417 - accuracy: 0.7072 - val_loss: 1.1039 - val_accuracy: 0.6900\n",
      "Epoch 26/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0385 - accuracy: 0.7082 - val_loss: 1.1008 - val_accuracy: 0.6904\n",
      "Epoch 27/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0355 - accuracy: 0.7091 - val_loss: 1.1011 - val_accuracy: 0.6920\n",
      "Epoch 28/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0325 - accuracy: 0.7090 - val_loss: 1.0981 - val_accuracy: 0.6922\n",
      "Epoch 29/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0297 - accuracy: 0.7106 - val_loss: 1.0960 - val_accuracy: 0.6936\n",
      "Epoch 30/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0268 - accuracy: 0.7118 - val_loss: 1.0978 - val_accuracy: 0.6926\n",
      "1032/1032 [==============================] - 2s 2ms/step\n",
      "[CV] END learning_rate=0.007231427441124776, n_hidden=0, n_units=274; total time= 1.2min\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_21 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 26)                20410     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20410 (79.73 KB)\n",
      "Trainable params: 20410 (79.73 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1032/1032 [==============================] - 3s 2ms/step - loss: 2.1955 - accuracy: 0.4560 - val_loss: 1.6949 - val_accuracy: 0.5752\n",
      "Epoch 2/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.5400 - accuracy: 0.5964 - val_loss: 1.4571 - val_accuracy: 0.6128\n",
      "Epoch 3/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.3835 - accuracy: 0.6225 - val_loss: 1.3623 - val_accuracy: 0.6276\n",
      "Epoch 4/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.3058 - accuracy: 0.6376 - val_loss: 1.3041 - val_accuracy: 0.6422\n",
      "Epoch 5/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.2567 - accuracy: 0.6486 - val_loss: 1.2661 - val_accuracy: 0.6474\n",
      "Epoch 6/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.2220 - accuracy: 0.6564 - val_loss: 1.2400 - val_accuracy: 0.6534\n",
      "Epoch 7/30\n",
      "1032/1032 [==============================] - 3s 2ms/step - loss: 1.1960 - accuracy: 0.6627 - val_loss: 1.2190 - val_accuracy: 0.6616\n",
      "Epoch 8/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.1745 - accuracy: 0.6684 - val_loss: 1.2015 - val_accuracy: 0.6682\n",
      "Epoch 9/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.1580 - accuracy: 0.6737 - val_loss: 1.1880 - val_accuracy: 0.6710\n",
      "Epoch 10/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.1438 - accuracy: 0.6780 - val_loss: 1.1743 - val_accuracy: 0.6730\n",
      "Epoch 11/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.1316 - accuracy: 0.6814 - val_loss: 1.1660 - val_accuracy: 0.6800\n",
      "Epoch 12/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.1209 - accuracy: 0.6844 - val_loss: 1.1561 - val_accuracy: 0.6786\n",
      "Epoch 13/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.1118 - accuracy: 0.6875 - val_loss: 1.1505 - val_accuracy: 0.6816\n",
      "Epoch 14/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.1036 - accuracy: 0.6901 - val_loss: 1.1441 - val_accuracy: 0.6840\n",
      "Epoch 15/30\n",
      "1032/1032 [==============================] - 3s 2ms/step - loss: 1.0963 - accuracy: 0.6917 - val_loss: 1.1382 - val_accuracy: 0.6878\n",
      "Epoch 16/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0897 - accuracy: 0.6940 - val_loss: 1.1339 - val_accuracy: 0.6878\n",
      "Epoch 17/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0837 - accuracy: 0.6949 - val_loss: 1.1300 - val_accuracy: 0.6854\n",
      "Epoch 18/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0785 - accuracy: 0.6969 - val_loss: 1.1241 - val_accuracy: 0.6916\n",
      "Epoch 19/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0733 - accuracy: 0.6988 - val_loss: 1.1223 - val_accuracy: 0.6900\n",
      "Epoch 20/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0687 - accuracy: 0.6995 - val_loss: 1.1182 - val_accuracy: 0.6912\n",
      "Epoch 21/30\n",
      "1032/1032 [==============================] - 3s 2ms/step - loss: 1.0641 - accuracy: 0.7014 - val_loss: 1.1149 - val_accuracy: 0.6940\n",
      "Epoch 22/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0605 - accuracy: 0.7023 - val_loss: 1.1110 - val_accuracy: 0.6920\n",
      "Epoch 23/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0565 - accuracy: 0.7031 - val_loss: 1.1091 - val_accuracy: 0.6940\n",
      "Epoch 24/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0529 - accuracy: 0.7039 - val_loss: 1.1071 - val_accuracy: 0.6942\n",
      "Epoch 25/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0496 - accuracy: 0.7059 - val_loss: 1.1064 - val_accuracy: 0.6948\n",
      "Epoch 26/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0467 - accuracy: 0.7059 - val_loss: 1.1018 - val_accuracy: 0.6948\n",
      "Epoch 27/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0434 - accuracy: 0.7074 - val_loss: 1.1009 - val_accuracy: 0.6962\n",
      "Epoch 28/30\n",
      "1032/1032 [==============================] - 3s 2ms/step - loss: 1.0407 - accuracy: 0.7077 - val_loss: 1.0991 - val_accuracy: 0.6964\n",
      "Epoch 29/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0381 - accuracy: 0.7082 - val_loss: 1.0975 - val_accuracy: 0.6958\n",
      "Epoch 30/30\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.0352 - accuracy: 0.7097 - val_loss: 1.0957 - val_accuracy: 0.6974\n",
      "1032/1032 [==============================] - 2s 1ms/step\n",
      "[CV] END learning_rate=0.007231427441124776, n_hidden=0, n_units=274; total time= 1.2min\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_22 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 206)               161710    \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 206)               42642     \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 26)                5382      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 209734 (819.27 KB)\n",
      "Trainable params: 209734 (819.27 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1032/1032 [==============================] - 4s 3ms/step - loss: 2.1406 - accuracy: 0.4385 - val_loss: 1.4042 - val_accuracy: 0.5964\n",
      "Epoch 2/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.2300 - accuracy: 0.6456 - val_loss: 1.1578 - val_accuracy: 0.6694\n",
      "Epoch 3/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 1.0438 - accuracy: 0.6973 - val_loss: 1.0421 - val_accuracy: 0.7018\n",
      "Epoch 4/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.9283 - accuracy: 0.7311 - val_loss: 0.9324 - val_accuracy: 0.7318\n",
      "Epoch 5/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.8402 - accuracy: 0.7574 - val_loss: 0.8762 - val_accuracy: 0.7478\n",
      "Epoch 6/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.7678 - accuracy: 0.7778 - val_loss: 0.7997 - val_accuracy: 0.7676\n",
      "Epoch 7/30\n",
      "1032/1032 [==============================] - 4s 3ms/step - loss: 0.7061 - accuracy: 0.7941 - val_loss: 0.7632 - val_accuracy: 0.7792\n",
      "Epoch 8/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.6540 - accuracy: 0.8101 - val_loss: 0.7214 - val_accuracy: 0.7922\n",
      "Epoch 9/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.6085 - accuracy: 0.8213 - val_loss: 0.6718 - val_accuracy: 0.8048\n",
      "Epoch 10/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5696 - accuracy: 0.8336 - val_loss: 0.6451 - val_accuracy: 0.8110\n",
      "Epoch 11/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5357 - accuracy: 0.8424 - val_loss: 0.6249 - val_accuracy: 0.8174\n",
      "Epoch 12/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5082 - accuracy: 0.8492 - val_loss: 0.5990 - val_accuracy: 0.8224\n",
      "Epoch 13/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.4824 - accuracy: 0.8578 - val_loss: 0.5820 - val_accuracy: 0.8274\n",
      "Epoch 14/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4599 - accuracy: 0.8633 - val_loss: 0.5685 - val_accuracy: 0.8298\n",
      "Epoch 15/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4398 - accuracy: 0.8693 - val_loss: 0.5466 - val_accuracy: 0.8370\n",
      "Epoch 16/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4212 - accuracy: 0.8747 - val_loss: 0.5341 - val_accuracy: 0.8404\n",
      "Epoch 17/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4042 - accuracy: 0.8794 - val_loss: 0.5241 - val_accuracy: 0.8438\n",
      "Epoch 18/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.3899 - accuracy: 0.8832 - val_loss: 0.5112 - val_accuracy: 0.8492\n",
      "Epoch 19/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3751 - accuracy: 0.8882 - val_loss: 0.5099 - val_accuracy: 0.8476\n",
      "Epoch 20/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3618 - accuracy: 0.8903 - val_loss: 0.4958 - val_accuracy: 0.8518\n",
      "Epoch 21/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3496 - accuracy: 0.8949 - val_loss: 0.4934 - val_accuracy: 0.8490\n",
      "Epoch 22/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.3379 - accuracy: 0.8982 - val_loss: 0.4765 - val_accuracy: 0.8582\n",
      "Epoch 23/30\n",
      "1032/1032 [==============================] - 4s 3ms/step - loss: 0.3263 - accuracy: 0.9009 - val_loss: 0.4741 - val_accuracy: 0.8568\n",
      "Epoch 24/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3166 - accuracy: 0.9040 - val_loss: 0.4691 - val_accuracy: 0.8612\n",
      "Epoch 25/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3067 - accuracy: 0.9071 - val_loss: 0.4651 - val_accuracy: 0.8572\n",
      "Epoch 26/30\n",
      "1032/1032 [==============================] - 4s 3ms/step - loss: 0.2977 - accuracy: 0.9097 - val_loss: 0.4709 - val_accuracy: 0.8556\n",
      "Epoch 27/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.2880 - accuracy: 0.9121 - val_loss: 0.4562 - val_accuracy: 0.8602\n",
      "Epoch 28/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.2798 - accuracy: 0.9142 - val_loss: 0.4566 - val_accuracy: 0.8656\n",
      "Epoch 29/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.2722 - accuracy: 0.9153 - val_loss: 0.4497 - val_accuracy: 0.8632\n",
      "Epoch 30/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.2646 - accuracy: 0.9178 - val_loss: 0.4475 - val_accuracy: 0.8654\n",
      "1032/1032 [==============================] - 3s 3ms/step\n",
      "[CV] END learning_rate=0.004994768260404264, n_hidden=2, n_units=206; total time= 1.8min\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_23 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 206)               161710    \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 206)               42642     \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 26)                5382      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 209734 (819.27 KB)\n",
      "Trainable params: 209734 (819.27 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1032/1032 [==============================] - 5s 4ms/step - loss: 2.1293 - accuracy: 0.4432 - val_loss: 1.4098 - val_accuracy: 0.6054\n",
      "Epoch 2/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 1.2323 - accuracy: 0.6442 - val_loss: 1.1525 - val_accuracy: 0.6694\n",
      "Epoch 3/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 1.0512 - accuracy: 0.6949 - val_loss: 1.0247 - val_accuracy: 0.7050\n",
      "Epoch 4/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.9371 - accuracy: 0.7285 - val_loss: 0.9298 - val_accuracy: 0.7318\n",
      "Epoch 5/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.8457 - accuracy: 0.7577 - val_loss: 0.8548 - val_accuracy: 0.7542\n",
      "Epoch 6/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.7718 - accuracy: 0.7774 - val_loss: 0.8010 - val_accuracy: 0.7672\n",
      "Epoch 7/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.7111 - accuracy: 0.7959 - val_loss: 0.7530 - val_accuracy: 0.7848\n",
      "Epoch 8/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.6585 - accuracy: 0.8093 - val_loss: 0.7048 - val_accuracy: 0.7936\n",
      "Epoch 9/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.6155 - accuracy: 0.8224 - val_loss: 0.6803 - val_accuracy: 0.7938\n",
      "Epoch 10/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5766 - accuracy: 0.8319 - val_loss: 0.6343 - val_accuracy: 0.8114\n",
      "Epoch 11/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5441 - accuracy: 0.8408 - val_loss: 0.6101 - val_accuracy: 0.8144\n",
      "Epoch 12/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5132 - accuracy: 0.8499 - val_loss: 0.5860 - val_accuracy: 0.8238\n",
      "Epoch 13/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.4882 - accuracy: 0.8564 - val_loss: 0.5726 - val_accuracy: 0.8286\n",
      "Epoch 14/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.4635 - accuracy: 0.8615 - val_loss: 0.5592 - val_accuracy: 0.8312\n",
      "Epoch 15/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4439 - accuracy: 0.8670 - val_loss: 0.5467 - val_accuracy: 0.8362\n",
      "Epoch 16/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4241 - accuracy: 0.8738 - val_loss: 0.5304 - val_accuracy: 0.8358\n",
      "Epoch 17/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.4067 - accuracy: 0.8781 - val_loss: 0.5189 - val_accuracy: 0.8446\n",
      "Epoch 18/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.3906 - accuracy: 0.8817 - val_loss: 0.5033 - val_accuracy: 0.8492\n",
      "Epoch 19/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3757 - accuracy: 0.8858 - val_loss: 0.5019 - val_accuracy: 0.8500\n",
      "Epoch 20/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3617 - accuracy: 0.8917 - val_loss: 0.4991 - val_accuracy: 0.8506\n",
      "Epoch 21/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3490 - accuracy: 0.8945 - val_loss: 0.4895 - val_accuracy: 0.8530\n",
      "Epoch 22/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3374 - accuracy: 0.8981 - val_loss: 0.4763 - val_accuracy: 0.8564\n",
      "Epoch 23/30\n",
      "1032/1032 [==============================] - 4s 3ms/step - loss: 0.3251 - accuracy: 0.9017 - val_loss: 0.4741 - val_accuracy: 0.8564\n",
      "Epoch 24/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3145 - accuracy: 0.9051 - val_loss: 0.4699 - val_accuracy: 0.8578\n",
      "Epoch 25/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.3054 - accuracy: 0.9075 - val_loss: 0.4686 - val_accuracy: 0.8572\n",
      "Epoch 26/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2954 - accuracy: 0.9101 - val_loss: 0.4554 - val_accuracy: 0.8620\n",
      "Epoch 27/30\n",
      "1032/1032 [==============================] - 4s 3ms/step - loss: 0.2870 - accuracy: 0.9134 - val_loss: 0.4555 - val_accuracy: 0.8602\n",
      "Epoch 28/30\n",
      "1032/1032 [==============================] - 4s 4ms/step - loss: 0.2781 - accuracy: 0.9144 - val_loss: 0.4568 - val_accuracy: 0.8606\n",
      "Epoch 29/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2709 - accuracy: 0.9171 - val_loss: 0.4537 - val_accuracy: 0.8642\n",
      "Epoch 30/30\n",
      "1032/1032 [==============================] - 3s 3ms/step - loss: 0.2626 - accuracy: 0.9194 - val_loss: 0.4546 - val_accuracy: 0.8654\n",
      "1032/1032 [==============================] - 2s 2ms/step\n",
      "[CV] END learning_rate=0.004994768260404264, n_hidden=2, n_units=206; total time= 1.8min\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_24 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 220)               172700    \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 220)               48620     \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 220)               48620     \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 26)                5746      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 275686 (1.05 MB)\n",
      "Trainable params: 275686 (1.05 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2064/2064 [==============================] - 9s 4ms/step - loss: 1.6892 - accuracy: 0.5333 - val_loss: 1.0919 - val_accuracy: 0.6756\n",
      "Epoch 2/30\n",
      "2064/2064 [==============================] - 6s 3ms/step - loss: 0.9078 - accuracy: 0.7338 - val_loss: 0.8179 - val_accuracy: 0.7596\n",
      "Epoch 3/30\n",
      "2064/2064 [==============================] - 8s 4ms/step - loss: 0.7004 - accuracy: 0.7930 - val_loss: 0.6655 - val_accuracy: 0.8032\n",
      "Epoch 4/30\n",
      "2064/2064 [==============================] - 7s 3ms/step - loss: 0.5804 - accuracy: 0.8265 - val_loss: 0.5788 - val_accuracy: 0.8260\n",
      "Epoch 5/30\n",
      "2064/2064 [==============================] - 7s 4ms/step - loss: 0.5046 - accuracy: 0.8476 - val_loss: 0.5172 - val_accuracy: 0.8436\n",
      "Epoch 6/30\n",
      "2064/2064 [==============================] - 7s 3ms/step - loss: 0.4513 - accuracy: 0.8628 - val_loss: 0.4813 - val_accuracy: 0.8538\n",
      "Epoch 7/30\n",
      "2064/2064 [==============================] - 7s 3ms/step - loss: 0.4113 - accuracy: 0.8735 - val_loss: 0.4629 - val_accuracy: 0.8558\n",
      "Epoch 8/30\n",
      "2064/2064 [==============================] - 7s 3ms/step - loss: 0.3794 - accuracy: 0.8819 - val_loss: 0.4396 - val_accuracy: 0.8654\n",
      "Epoch 9/30\n",
      "2064/2064 [==============================] - 7s 3ms/step - loss: 0.3539 - accuracy: 0.8898 - val_loss: 0.4234 - val_accuracy: 0.8674\n",
      "Epoch 10/30\n",
      "2064/2064 [==============================] - 8s 4ms/step - loss: 0.3330 - accuracy: 0.8948 - val_loss: 0.4079 - val_accuracy: 0.8750\n",
      "Epoch 11/30\n",
      "2064/2064 [==============================] - 7s 3ms/step - loss: 0.3130 - accuracy: 0.9013 - val_loss: 0.4143 - val_accuracy: 0.8710\n",
      "Epoch 12/30\n",
      "2064/2064 [==============================] - 8s 4ms/step - loss: 0.2972 - accuracy: 0.9051 - val_loss: 0.4010 - val_accuracy: 0.8712\n",
      "Epoch 13/30\n",
      "2064/2064 [==============================] - 7s 3ms/step - loss: 0.2824 - accuracy: 0.9090 - val_loss: 0.4102 - val_accuracy: 0.8702\n",
      "Epoch 14/30\n",
      "2064/2064 [==============================] - 7s 3ms/step - loss: 0.2683 - accuracy: 0.9146 - val_loss: 0.3889 - val_accuracy: 0.8802\n",
      "Epoch 15/30\n",
      "2064/2064 [==============================] - 7s 3ms/step - loss: 0.2555 - accuracy: 0.9167 - val_loss: 0.3770 - val_accuracy: 0.8852\n",
      "Epoch 16/30\n",
      "2064/2064 [==============================] - 7s 3ms/step - loss: 0.2450 - accuracy: 0.9201 - val_loss: 0.3698 - val_accuracy: 0.8880\n",
      "Epoch 17/30\n",
      "2064/2064 [==============================] - 7s 4ms/step - loss: 0.2349 - accuracy: 0.9228 - val_loss: 0.3563 - val_accuracy: 0.8938\n",
      "Epoch 18/30\n",
      "2064/2064 [==============================] - 6s 3ms/step - loss: 0.2257 - accuracy: 0.9264 - val_loss: 0.3563 - val_accuracy: 0.8908\n",
      "Epoch 19/30\n",
      "2064/2064 [==============================] - 8s 4ms/step - loss: 0.2164 - accuracy: 0.9279 - val_loss: 0.3637 - val_accuracy: 0.8868\n",
      "Epoch 20/30\n",
      "2064/2064 [==============================] - 7s 3ms/step - loss: 0.2080 - accuracy: 0.9316 - val_loss: 0.3554 - val_accuracy: 0.8926\n",
      "Epoch 21/30\n",
      "2064/2064 [==============================] - 7s 4ms/step - loss: 0.1999 - accuracy: 0.9332 - val_loss: 0.3614 - val_accuracy: 0.8922\n",
      "Epoch 22/30\n",
      "2064/2064 [==============================] - 7s 3ms/step - loss: 0.1916 - accuracy: 0.9359 - val_loss: 0.3550 - val_accuracy: 0.8920\n",
      "Epoch 23/30\n",
      "2064/2064 [==============================] - 7s 3ms/step - loss: 0.1862 - accuracy: 0.9369 - val_loss: 0.3597 - val_accuracy: 0.8890\n",
      "Epoch 24/30\n",
      "2064/2064 [==============================] - 7s 3ms/step - loss: 0.1789 - accuracy: 0.9396 - val_loss: 0.3608 - val_accuracy: 0.8904\n",
      "Epoch 25/30\n",
      "2064/2064 [==============================] - 7s 3ms/step - loss: 0.1724 - accuracy: 0.9423 - val_loss: 0.3509 - val_accuracy: 0.8948\n",
      "Epoch 26/30\n",
      "2064/2064 [==============================] - 7s 4ms/step - loss: 0.1659 - accuracy: 0.9435 - val_loss: 0.3513 - val_accuracy: 0.8970\n",
      "Epoch 27/30\n",
      "2064/2064 [==============================] - 7s 3ms/step - loss: 0.1600 - accuracy: 0.9459 - val_loss: 0.3640 - val_accuracy: 0.8920\n",
      "Epoch 28/30\n",
      "2064/2064 [==============================] - 7s 4ms/step - loss: 0.1550 - accuracy: 0.9471 - val_loss: 0.3691 - val_accuracy: 0.8884\n",
      "Epoch 29/30\n",
      "2064/2064 [==============================] - 7s 3ms/step - loss: 0.1496 - accuracy: 0.9489 - val_loss: 0.3685 - val_accuracy: 0.8930\n",
      "Epoch 30/30\n",
      "2064/2064 [==============================] - 7s 4ms/step - loss: 0.1445 - accuracy: 0.9508 - val_loss: 0.3562 - val_accuracy: 0.8972\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=2,\n",
       "                   estimator=KerasClassifier(learning_rate=0.001, loss=&#x27;sparse_categorical_crossentropy&#x27;, model=&lt;function build_model at 0x0000017A3307F250&gt;, n_hidden=1, n_units=1),\n",
       "                   n_iter=12,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: [0.0014281792432503887,\n",
       "                                                          0.007129011532164708,\n",
       "                                                          0.04976414902226644,\n",
       "                                                          0.03933421580821964,\n",
       "                                                          0.048689543597302466,\n",
       "                                                          0.01542711134685262...\n",
       "                                                          0.0082901121792055,\n",
       "                                                          0.005951873131359952,\n",
       "                                                          0.007782188172779695,\n",
       "                                                          0.002772785203442673,\n",
       "                                                          0.01007820083211063,\n",
       "                                                          0.013330442925950911,\n",
       "                                                          0.023486162877083185,\n",
       "                                                          0.010054742063861833,\n",
       "                                                          0.019254915380726156,\n",
       "                                                          0.0019399055609425407,\n",
       "                                                          0.0016057646282152133, ...],\n",
       "                                        &#x27;n_hidden&#x27;: [0, 1, 2, 3],\n",
       "                                        &#x27;n_units&#x27;: [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                    10, 11, 12, 13, 14, 15, 16,\n",
       "                                                    17, 18, 19, 20, 21, 22, 23,\n",
       "                                                    24, 25, 26, 27, 28, 29, 30, ...]},\n",
       "                   verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=2,\n",
       "                   estimator=KerasClassifier(learning_rate=0.001, loss=&#x27;sparse_categorical_crossentropy&#x27;, model=&lt;function build_model at 0x0000017A3307F250&gt;, n_hidden=1, n_units=1),\n",
       "                   n_iter=12,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: [0.0014281792432503887,\n",
       "                                                          0.007129011532164708,\n",
       "                                                          0.04976414902226644,\n",
       "                                                          0.03933421580821964,\n",
       "                                                          0.048689543597302466,\n",
       "                                                          0.01542711134685262...\n",
       "                                                          0.0082901121792055,\n",
       "                                                          0.005951873131359952,\n",
       "                                                          0.007782188172779695,\n",
       "                                                          0.002772785203442673,\n",
       "                                                          0.01007820083211063,\n",
       "                                                          0.013330442925950911,\n",
       "                                                          0.023486162877083185,\n",
       "                                                          0.010054742063861833,\n",
       "                                                          0.019254915380726156,\n",
       "                                                          0.0019399055609425407,\n",
       "                                                          0.0016057646282152133, ...],\n",
       "                                        &#x27;n_hidden&#x27;: [0, 1, 2, 3],\n",
       "                                        &#x27;n_units&#x27;: [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                    10, 11, 12, 13, 14, 15, 16,\n",
       "                                                    17, 18, 19, 20, 21, 22, 23,\n",
       "                                                    24, 25, 26, 27, 28, 29, 30, ...]},\n",
       "                   verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>KerasClassifier(\n",
       "\tmodel=&lt;function build_model at 0x0000017A3307F250&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=sparse_categorical_crossentropy\n",
       "\tmetrics=None\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=1\n",
       "\tn_units=1\n",
       "\tn_hidden=1\n",
       "\tlearning_rate=0.001\n",
       "\tclass_weight=None\n",
       ")</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>KerasClassifier(\n",
       "\tmodel=&lt;function build_model at 0x0000017A3307F250&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=sparse_categorical_crossentropy\n",
       "\tmetrics=None\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=1\n",
       "\tn_units=1\n",
       "\tn_hidden=1\n",
       "\tlearning_rate=0.001\n",
       "\tclass_weight=None\n",
       ")</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=2,\n",
       "                   estimator=KerasClassifier(learning_rate=0.001, loss='sparse_categorical_crossentropy', model=<function build_model at 0x0000017A3307F250>, n_hidden=1, n_units=1),\n",
       "                   n_iter=12,\n",
       "                   param_distributions={'learning_rate': [0.0014281792432503887,\n",
       "                                                          0.007129011532164708,\n",
       "                                                          0.04976414902226644,\n",
       "                                                          0.03933421580821964,\n",
       "                                                          0.048689543597302466,\n",
       "                                                          0.01542711134685262...\n",
       "                                                          0.0082901121792055,\n",
       "                                                          0.005951873131359952,\n",
       "                                                          0.007782188172779695,\n",
       "                                                          0.002772785203442673,\n",
       "                                                          0.01007820083211063,\n",
       "                                                          0.013330442925950911,\n",
       "                                                          0.023486162877083185,\n",
       "                                                          0.010054742063861833,\n",
       "                                                          0.019254915380726156,\n",
       "                                                          0.0019399055609425407,\n",
       "                                                          0.0016057646282152133, ...],\n",
       "                                        'n_hidden': [0, 1, 2, 3],\n",
       "                                        'n_units': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                    10, 11, 12, 13, 14, 15, 16,\n",
       "                                                    17, 18, 19, 20, 21, 22, 23,\n",
       "                                                    24, 25, 26, 27, 28, 29, 30, ...]},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "import sklearn\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#dizionario contenente alcune distribuzioni di parametri che possono\n",
    "#essere utilizzate durante l'ottimizzazione dei parametri di un modello\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3], #range di numeri di layer da provare\n",
    "    \"n_units\": np.arange(1, 300).tolist(), #range delle unita\n",
    "    \"learning_rate\": reciprocal(1e-3, 5e-2).rvs(1000).tolist(), #range del lr\n",
    "}\n",
    "\n",
    "# wrapper\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "#creo un classificatore Keras utilizzando l'interfaccia di Scikit-learn.\n",
    "keras_clf = KerasClassifier(\n",
    "    model=build_model, #modello da utilizzare\n",
    "    loss=\"sparse_categorical_crossentropy\", #loss da utilizzare\n",
    "    n_units=1, n_hidden=1, learning_rate=0.001 # necessary to assign a value here, to make them visible (and tunable) to scikit-learn\n",
    ") #Questi valori iniziali sono necessari perch√© Scikit-learn richiede di assegnare dei valori a tutti i parametri del modello durante \n",
    "  #la creazione dell'istanza. Tuttavia, durante la ricerca degli iperparametri, questi valori potrebbero essere sovrascritti\n",
    "\n",
    "\n",
    "#n_iter Specifica il numero di combinazioni di iperparametri diverse che verranno testate durante la ricerca casuale\n",
    "#cv Specifica il numero di fold nella cross-validation\n",
    "#verbose Controlla il livello di verbosit√† durante l'addestramento e la validazione. sono i messaggi che mi lascia\n",
    "rnd_search_cv = RandomizedSearchCV(keras_clf, param_distribs, n_iter=12, cv=2, verbose=2) #saranno 50 addestramenti da 45 epoche\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=30,\n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3a82fd6-3a16-4631-a2f8-74e8cf41fe47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_units': 220, 'n_hidden': 3, 'learning_rate': 0.0051596519805228586}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_ #restituisce gli iperparametri migliori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96546e2b-44ef-410b-8fdb-e4651eddaf19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_24 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 220)               172700    \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 220)               48620     \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 220)               48620     \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 26)                5746      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 275686 (1.05 MB)\n",
      "Trainable params: 275686 (1.05 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = rnd_search_cv.best_estimator_.model_\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b6f3281-c7e6-49ad-9783-f83048d85aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "555/555 [==============================] - 2s 3ms/step - loss: 0.3322 - accuracy: 0.8981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3321630656719208, 0.8980855941772461]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test) #valutazione del modello con gli iperparametri trovati sul test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "826f16f7-0fba-4a6c-ba59-2535a3268a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definisco un modello di rete neurale sequenziale utilizzando TensorFlow e Keras\n",
    "model_best = keras.models.Sequential()\n",
    "model_best.add(keras.layers.Flatten(input_shape=[28, 28])) #input di immagini 28x28\n",
    "model_best.add(keras.layers.Dense(220, activation=\"relu\")) #primo stato nascosto. f di attivazione relu\n",
    "model_best.add(keras.layers.Dense(220, activation=\"relu\")) #secondo strato nascosto. f di attivazione relu\n",
    "model_best.add(keras.layers.Dense(220, activation=\"relu\")) #terzo strato nascosto. f di attivazione relu\n",
    "model_best.add(keras.layers.Dense(26, activation=\"softmax\")) #26 etichette finali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7961359c-c878-45e1-8107-4f20fa143e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0051596519805228586\n",
    "\n",
    "model_best.compile(loss=\"sparse_categorical_crossentropy\", #funzione di perdita utilizzata\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=lr), #ottimizzatore, stochastic gradient descent\n",
    "              metrics=[\"accuracy\"]) #matrica->accuracy (percentuale predizioni corrette su totali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa006d3e-eea9-4d09-9c89-03592c31997b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2064/2064 [==============================] - 8s 3ms/step - loss: 0.6698 - accuracy: 0.8048 - val_loss: 0.6693 - val_accuracy: 0.8000\n",
      "Epoch 2/30\n",
      "2064/2064 [==============================] - 6s 3ms/step - loss: 0.6064 - accuracy: 0.8211 - val_loss: 0.6211 - val_accuracy: 0.8168\n",
      "Epoch 3/30\n",
      "2064/2064 [==============================] - 7s 4ms/step - loss: 0.5572 - accuracy: 0.8347 - val_loss: 0.5859 - val_accuracy: 0.8248\n",
      "Epoch 4/30\n",
      "2064/2064 [==============================] - 6s 3ms/step - loss: 0.5164 - accuracy: 0.8460 - val_loss: 0.5494 - val_accuracy: 0.8334\n",
      "Epoch 5/30\n",
      "2064/2064 [==============================] - 8s 4ms/step - loss: 0.4830 - accuracy: 0.8558 - val_loss: 0.5171 - val_accuracy: 0.8438\n",
      "Epoch 6/30\n",
      "2064/2064 [==============================] - 8s 4ms/step - loss: 0.4549 - accuracy: 0.8634 - val_loss: 0.4942 - val_accuracy: 0.8468\n",
      "Epoch 7/30\n",
      "2064/2064 [==============================] - 9s 4ms/step - loss: 0.4302 - accuracy: 0.8702 - val_loss: 0.4814 - val_accuracy: 0.8504\n",
      "Epoch 8/30\n",
      "2064/2064 [==============================] - 7s 3ms/step - loss: 0.4084 - accuracy: 0.8763 - val_loss: 0.4593 - val_accuracy: 0.8606\n",
      "Epoch 9/30\n",
      "2064/2064 [==============================] - 8s 4ms/step - loss: 0.3894 - accuracy: 0.8809 - val_loss: 0.4519 - val_accuracy: 0.8600\n",
      "Epoch 10/30\n",
      "2064/2064 [==============================] - 7s 3ms/step - loss: 0.3734 - accuracy: 0.8845 - val_loss: 0.4389 - val_accuracy: 0.8636\n",
      "Epoch 11/30\n",
      "2064/2064 [==============================] - 8s 4ms/step - loss: 0.3574 - accuracy: 0.8906 - val_loss: 0.4365 - val_accuracy: 0.8654\n",
      "Epoch 12/30\n",
      "2064/2064 [==============================] - 7s 4ms/step - loss: 0.3440 - accuracy: 0.8929 - val_loss: 0.4315 - val_accuracy: 0.8650\n",
      "Epoch 13/30\n",
      "2064/2064 [==============================] - 8s 4ms/step - loss: 0.3318 - accuracy: 0.8975 - val_loss: 0.4301 - val_accuracy: 0.8670\n",
      "Epoch 14/30\n",
      "2064/2064 [==============================] - 7s 3ms/step - loss: 0.3199 - accuracy: 0.9006 - val_loss: 0.4035 - val_accuracy: 0.8720\n",
      "Epoch 15/30\n",
      "2064/2064 [==============================] - 8s 4ms/step - loss: 0.3094 - accuracy: 0.9033 - val_loss: 0.4061 - val_accuracy: 0.8756\n",
      "Epoch 16/30\n",
      "2064/2064 [==============================] - 8s 4ms/step - loss: 0.2997 - accuracy: 0.9060 - val_loss: 0.3943 - val_accuracy: 0.8754\n",
      "Epoch 17/30\n",
      "2064/2064 [==============================] - 8s 4ms/step - loss: 0.2908 - accuracy: 0.9085 - val_loss: 0.3844 - val_accuracy: 0.8816\n",
      "Epoch 18/30\n",
      "2064/2064 [==============================] - 8s 4ms/step - loss: 0.2821 - accuracy: 0.9108 - val_loss: 0.3799 - val_accuracy: 0.8838\n",
      "Epoch 19/30\n",
      "2064/2064 [==============================] - 8s 4ms/step - loss: 0.2738 - accuracy: 0.9125 - val_loss: 0.3839 - val_accuracy: 0.8804\n",
      "Epoch 20/30\n",
      "2064/2064 [==============================] - 9s 4ms/step - loss: 0.2663 - accuracy: 0.9152 - val_loss: 0.3708 - val_accuracy: 0.8812\n",
      "Epoch 21/30\n",
      "2064/2064 [==============================] - 8s 4ms/step - loss: 0.2594 - accuracy: 0.9167 - val_loss: 0.3726 - val_accuracy: 0.8844\n",
      "Epoch 22/30\n",
      "2064/2064 [==============================] - 8s 4ms/step - loss: 0.2521 - accuracy: 0.9185 - val_loss: 0.3730 - val_accuracy: 0.8848\n",
      "Epoch 23/30\n",
      "2064/2064 [==============================] - 7s 4ms/step - loss: 0.2458 - accuracy: 0.9215 - val_loss: 0.3704 - val_accuracy: 0.8844\n",
      "Epoch 24/30\n",
      "2064/2064 [==============================] - 8s 4ms/step - loss: 0.2396 - accuracy: 0.9221 - val_loss: 0.3719 - val_accuracy: 0.8846\n",
      "Epoch 25/30\n",
      "2064/2064 [==============================] - 8s 4ms/step - loss: 0.2338 - accuracy: 0.9248 - val_loss: 0.3675 - val_accuracy: 0.8876\n",
      "Epoch 26/30\n",
      "2064/2064 [==============================] - 8s 4ms/step - loss: 0.2282 - accuracy: 0.9258 - val_loss: 0.3577 - val_accuracy: 0.8924\n",
      "Epoch 27/30\n",
      "2064/2064 [==============================] - 8s 4ms/step - loss: 0.2220 - accuracy: 0.9289 - val_loss: 0.3628 - val_accuracy: 0.8884\n",
      "Epoch 28/30\n",
      "2064/2064 [==============================] - 9s 4ms/step - loss: 0.2174 - accuracy: 0.9290 - val_loss: 0.3611 - val_accuracy: 0.8892\n",
      "Epoch 29/30\n",
      "2064/2064 [==============================] - 7s 4ms/step - loss: 0.2124 - accuracy: 0.9308 - val_loss: 0.3695 - val_accuracy: 0.8882\n",
      "Epoch 30/30\n",
      "2064/2064 [==============================] - 8s 4ms/step - loss: 0.2074 - accuracy: 0.9327 - val_loss: 0.3601 - val_accuracy: 0.8912\n"
     ]
    }
   ],
   "source": [
    "history = model_best.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0b37bc0-1155-4714-a138-27bf917d4e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1f200e-35ed-48a3-ad2d-ba501cf807a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
